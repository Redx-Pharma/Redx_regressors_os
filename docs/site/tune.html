<!doctype html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />


  <title>redxregressors.tune API documentation</title>
  <meta name="description" content="Module for tuning hyper-parameters for a model using Optuna" />


  <link href='https://fonts.googleapis.com/css?family=Source+Sans+Pro:400,300' rel='stylesheet' type='text/css'>

  <style type="text/css">
* {
  box-sizing: border-box;
}
/*! normalize.css v1.1.1 | MIT License | git.io/normalize */

/* ==========================================================================
   HTML5 display definitions
   ========================================================================== */

/**
 * Correct `block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

article,
aside,
details,
figcaption,
figure,
footer,
header,
hgroup,
main,
nav,
section,
summary {
    display: block;
}

/**
 * Correct `inline-block` display not defined in IE 6/7/8/9 and Firefox 3.
 */

audio,
canvas,
video {
    display: inline-block;
    *display: inline;
    *zoom: 1;
}

/**
 * Prevent modern browsers from displaying `audio` without controls.
 * Remove excess height in iOS 5 devices.
 */

audio:not([controls]) {
    display: none;
    height: 0;
}

/**
 * Address styling not present in IE 7/8/9, Firefox 3, and Safari 4.
 * Known issue: no IE 6 support.
 */

[hidden] {
    display: none;
}

/* ==========================================================================
   Base
   ========================================================================== */

/**
 * 1. Prevent system color scheme's background color being used in Firefox, IE,
 *    and Opera.
 * 2. Prevent system color scheme's text color being used in Firefox, IE, and
 *    Opera.
 * 3. Correct text resizing oddly in IE 6/7 when body `font-size` is set using
 *    `em` units.
 * 4. Prevent iOS text size adjust after orientation change, without disabling
 *    user zoom.
 */

html {
    background: #fff; /* 1 */
    color: #000; /* 2 */
    font-size: 100%; /* 3 */
    -webkit-text-size-adjust: 100%; /* 4 */
    -ms-text-size-adjust: 100%; /* 4 */
}

/**
 * Address `font-family` inconsistency between `textarea` and other form
 * elements.
 */

html,
button,
input,
select,
textarea {
    font-family: sans-serif;
}

/**
 * Address margins handled incorrectly in IE 6/7.
 */

body {
    margin: 0;
}

/* ==========================================================================
   Links
   ========================================================================== */

/**
 * Address `outline` inconsistency between Chrome and other browsers.
 */

a:focus {
    outline: thin dotted;
}

/**
 * Improve readability when focused and also mouse hovered in all browsers.
 */

a:active,
a:hover {
    outline: 0;
}

/* ==========================================================================
   Typography
   ========================================================================== */

/**
 * Address font sizes and margins set differently in IE 6/7.
 * Address font sizes within `section` and `article` in Firefox 4+, Safari 5,
 * and Chrome.
 */

h1 {
    font-size: 2em;
    margin: 0.67em 0;
}

h2 {
    font-size: 1.5em;
    margin: 0.83em 0;
}

h3 {
    font-size: 1.17em;
    margin: 1em 0;
}

h4 {
    font-size: 1em;
    margin: 1.33em 0;
}

h5 {
    font-size: 0.83em;
    margin: 1.67em 0;
}

h6 {
    font-size: 0.67em;
    margin: 2.33em 0;
}

/**
 * Address styling not present in IE 7/8/9, Safari 5, and Chrome.
 */

abbr[title] {
    border-bottom: 1px dotted;
}

/**
 * Address style set to `bolder` in Firefox 3+, Safari 4/5, and Chrome.
 */

b,
strong {
    font-weight: bold;
}

blockquote {
    margin: 1em 40px;
}

/**
 * Address styling not present in Safari 5 and Chrome.
 */

dfn {
    font-style: italic;
}

/**
 * Address differences between Firefox and other browsers.
 * Known issue: no IE 6/7 normalization.
 */

hr {
    -moz-box-sizing: content-box;
    box-sizing: content-box;
    height: 0;
}

/**
 * Address styling not present in IE 6/7/8/9.
 */

mark {
    background: #ff0;
    color: #000;
}

/**
 * Address margins set differently in IE 6/7.
 */

p,
pre {
    margin: 1em 0;
}

/**
 * Correct font family set oddly in IE 6, Safari 4/5, and Chrome.
 */

code,
kbd,
pre,
samp {
    font-family: monospace, serif;
    _font-family: 'courier new', monospace;
    font-size: 1em;
}

/**
 * Improve readability of pre-formatted text in all browsers.
 */

pre {
    white-space: pre;
    white-space: pre-wrap;
    word-wrap: break-word;
}

/**
 * Address CSS quotes not supported in IE 6/7.
 */

q {
    quotes: none;
}

/**
 * Address `quotes` property not supported in Safari 4.
 */

q:before,
q:after {
    content: '';
    content: none;
}

/**
 * Address inconsistent and variable font size in all browsers.
 */

small {
    font-size: 80%;
}

/**
 * Prevent `sub` and `sup` affecting `line-height` in all browsers.
 */

sub,
sup {
    font-size: 75%;
    line-height: 0;
    position: relative;
    vertical-align: baseline;
}

sup {
    top: -0.5em;
}

sub {
    bottom: -0.25em;
}

/* ==========================================================================
   Lists
   ========================================================================== */

/**
 * Address margins set differently in IE 6/7.
 */

dl,
menu,
ol,
ul {
    margin: 1em 0;
}

dd {
    margin: 0 0 0 40px;
}

/**
 * Address paddings set differently in IE 6/7.
 */

menu,
ol,
ul {
    padding: 0 0 0 40px;
}

/**
 * Correct list images handled incorrectly in IE 7.
 */

nav ul,
nav ol {
    list-style: none;
    list-style-image: none;
}

/* ==========================================================================
   Embedded content
   ========================================================================== */

/**
 * 1. Remove border when inside `a` element in IE 6/7/8/9 and Firefox 3.
 * 2. Improve image quality when scaled in IE 7.
 */

img {
    border: 0; /* 1 */
    -ms-interpolation-mode: bicubic; /* 2 */
}

/**
 * Correct overflow displayed oddly in IE 9.
 */

svg:not(:root) {
    overflow: hidden;
}

/* ==========================================================================
   Figures
   ========================================================================== */

/**
 * Address margin not present in IE 6/7/8/9, Safari 5, and Opera 11.
 */

figure {
    margin: 0;
}

/* ==========================================================================
   Forms
   ========================================================================== */

/**
 * Correct margin displayed oddly in IE 6/7.
 */

form {
    margin: 0;
}

/**
 * Define consistent border, margin, and padding.
 */

fieldset {
    border: 1px solid #c0c0c0;
    margin: 0 2px;
    padding: 0.35em 0.625em 0.75em;
}

/**
 * 1. Correct color not being inherited in IE 6/7/8/9.
 * 2. Correct text not wrapping in Firefox 3.
 * 3. Correct alignment displayed oddly in IE 6/7.
 */

legend {
    border: 0; /* 1 */
    padding: 0;
    white-space: normal; /* 2 */
    *margin-left: -7px; /* 3 */
}

/**
 * 1. Correct font size not being inherited in all browsers.
 * 2. Address margins set differently in IE 6/7, Firefox 3+, Safari 5,
 *    and Chrome.
 * 3. Improve appearance and consistency in all browsers.
 */

button,
input,
select,
textarea {
    font-size: 100%; /* 1 */
    margin: 0; /* 2 */
    vertical-align: baseline; /* 3 */
    *vertical-align: middle; /* 3 */
}

/**
 * Address Firefox 3+ setting `line-height` on `input` using `!important` in
 * the UA stylesheet.
 */

button,
input {
    line-height: normal;
}

/**
 * Address inconsistent `text-transform` inheritance for `button` and `select`.
 * All other form control elements do not inherit `text-transform` values.
 * Correct `button` style inheritance in Chrome, Safari 5+, and IE 6+.
 * Correct `select` style inheritance in Firefox 4+ and Opera.
 */

button,
select {
    text-transform: none;
}

/**
 * 1. Avoid the WebKit bug in Android 4.0.* where (2) destroys native `audio`
 *    and `video` controls.
 * 2. Correct inability to style clickable `input` types in iOS.
 * 3. Improve usability and consistency of cursor style between image-type
 *    `input` and others.
 * 4. Remove inner spacing in IE 7 without affecting normal text inputs.
 *    Known issue: inner spacing remains in IE 6.
 */

button,
html input[type="button"], /* 1 */
input[type="reset"],
input[type="submit"] {
    -webkit-appearance: button; /* 2 */
    cursor: pointer; /* 3 */
    *overflow: visible;  /* 4 */
}

/**
 * Re-set default cursor for disabled elements.
 */

button[disabled],
html input[disabled] {
    cursor: default;
}

/**
 * 1. Address box sizing set to content-box in IE 8/9.
 * 2. Remove excess padding in IE 8/9.
 * 3. Remove excess padding in IE 7.
 *    Known issue: excess padding remains in IE 6.
 */

input[type="checkbox"],
input[type="radio"] {
    box-sizing: border-box; /* 1 */
    padding: 0; /* 2 */
    *height: 13px; /* 3 */
    *width: 13px; /* 3 */
}

/**
 * 1. Address `appearance` set to `searchfield` in Safari 5 and Chrome.
 * 2. Address `box-sizing` set to `border-box` in Safari 5 and Chrome
 *    (include `-moz` to future-proof).
 */

input[type="search"] {
    -webkit-appearance: textfield; /* 1 */
    -moz-box-sizing: content-box;
    -webkit-box-sizing: content-box; /* 2 */
    box-sizing: content-box;
}

/**
 * Remove inner padding and search cancel button in Safari 5 and Chrome
 * on OS X.
 */

input[type="search"]::-webkit-search-cancel-button,
input[type="search"]::-webkit-search-decoration {
    -webkit-appearance: none;
}

/**
 * Remove inner padding and border in Firefox 3+.
 */

button::-moz-focus-inner,
input::-moz-focus-inner {
    border: 0;
    padding: 0;
}

/**
 * 1. Remove default vertical scrollbar in IE 6/7/8/9.
 * 2. Improve readability and alignment in all browsers.
 */

textarea {
    overflow: auto; /* 1 */
    vertical-align: top; /* 2 */
}

/* ==========================================================================
   Tables
   ========================================================================== */

/**
 * Remove most spacing between table cells.
 */

table {
    border-collapse: collapse;
    border-spacing: 0;
}
</style>
  <style type="text/css">
  html, body {
    margin: 0;
    padding: 0;
    min-height: 100%;
  }
  body {
    background: #fff;
    font-family: "Source Sans Pro", "Helvetica Neueue", Helvetica, sans;
    font-weight: 300;
    font-size: 16px;
    line-height: 1.6em;
  }
  #content {
    width: 70%;
    max-width: 850px;
    float: left;
    padding: 30px 60px;
    border-left: 1px solid #ddd;
  }
  #sidebar {
    width: 25%;
    float: left;
    padding: 30px;
    overflow: hidden;
  }
  #nav {
    font-size: 130%;
    margin: 0 0 15px 0;
  }

  #top {
    display: block;
    position: fixed;
    bottom: 5px;
    left: 5px;
    font-size: .85em;
    text-transform: uppercase;
  }

  #footer {
    font-size: .75em;
    padding: 5px 30px;
    border-top: 1px solid #ddd;
    text-align: right;
  }
    #footer p {
      margin: 0 0 0 30px;
      display: inline-block;
    }

  h1, h2, h3, h4, h5 {
    font-weight: 300;
  }
  h1 {
    font-size: 2.5em;
    line-height: 1.1em;
    margin: 0 0 .50em 0;
  }

  h2 {
    font-size: 1.75em;
    margin: 1em 0 .50em 0;
  }

  h3 {
    margin: 25px 0 10px 0;
  }

  h4 {
    margin: 0;
    font-size: 105%;
  }

  a {
    color: #058;
    text-decoration: none;
    transition: color .3s ease-in-out;
  }

  a:hover {
    color: #e08524;
    transition: color .3s ease-in-out;
  }

  pre, code, .mono, .name {
    font-family: "Ubuntu Mono", "Cousine", "DejaVu Sans Mono", monospace;
  }

  .title .name {
    font-weight: bold;
  }
  .section-title {
    margin-top: 2em;
  }
  .ident {
    color: #900;
  }

  code {
    background: #f9f9f9;
  }

  pre {
    background: #fefefe;
    border: 1px solid #ddd;
    box-shadow: 2px 2px 0 #f3f3f3;
    margin: 0 30px;
    padding: 15px 30px;
  }

  .codehilite {
    margin: 0 30px 10px 30px;
  }

    .codehilite pre {
      margin: 0;
    }
    .codehilite .err { background: #ff3300; color: #fff !important; }

  table#module-list {
    font-size: 110%;
  }

    table#module-list tr td:first-child {
      padding-right: 10px;
      white-space: nowrap;
    }

    table#module-list td {
      vertical-align: top;
      padding-bottom: 8px;
    }

      table#module-list td p {
        margin: 0 0 7px 0;
      }

  .def {
    display: table;
  }

    .def p {
      display: table-cell;
      vertical-align: top;
      text-align: left;
    }

    .def p:first-child {
      white-space: nowrap;
    }

    .def p:last-child {
      width: 100%;
    }


  #index {
    list-style-type: none;
    margin: 0;
    padding: 0;
  }
    ul#index .class_name {
      /* font-size: 110%; */
      font-weight: bold;
    }
    #index ul {
      margin: 0;
    }

  .item {
    margin: 0 0 15px 0;
  }

    .item .class {
      margin: 0 0 25px 30px;
    }

      .item .class ul.class_list {
        margin: 0 0 20px 0;
      }

    .item .name {
      background: #fafafa;
      margin: 0;
      font-weight: bold;
      padding: 5px 10px;
      border-radius: 3px;
      display: inline-block;
      min-width: 40%;
    }
      .item .name:hover {
        background: #f6f6f6;
      }

    .item .empty_desc {
      margin: 0 0 5px 0;
      padding: 0;
    }

    .item .inheritance {
      margin: 3px 0 0 30px;
    }

    .item .inherited {
      color: #666;
    }

    .item .desc {
      padding: 0 8px;
      margin: 0;
    }

      .item .desc p {
        margin: 0 0 10px 0;
      }

    .source_cont {
      margin: 0;
      padding: 0;
    }

    .source_link a {
      background: #ffc300;
      font-weight: 400;
      font-size: .75em;
      text-transform: uppercase;
      color: #fff;
      text-shadow: 1px 1px 0 #f4b700;

      padding: 3px 8px;
      border-radius: 2px;
      transition: background .3s ease-in-out;
    }
      .source_link a:hover {
        background: #FF7200;
        text-shadow: none;
        transition: background .3s ease-in-out;
      }

    .source {
      display: none;
      max-height: 600px;
      overflow-y: scroll;
      margin-bottom: 15px;
    }

      .source .codehilite {
        margin: 0;
      }

  .desc h1, .desc h2, .desc h3 {
    font-size: 100% !important;
  }
  .clear {
    clear: both;
  }

  @media all and (max-width: 950px) {
    #sidebar {
      width: 35%;
    }
    #content {
      width: 65%;
    }
  }
  @media all and (max-width: 650px) {
    #top {
      display: none;
    }
    #sidebar {
      float: none;
      width: auto;
    }
    #content {
      float: none;
      width: auto;
      padding: 30px;
    }

    #index ul {
      padding: 0;
      margin-bottom: 15px;
    }
    #index ul li {
      display: inline-block;
      margin-right: 30px;
    }
    #footer {
      text-align: left;
    }
    #footer p {
      display: block;
      margin: inherit;
    }
  }

  /*****************************/
</style>
  <style type="text/css">
  pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
.codehilite .hll { background-color: #ffffcc }
.codehilite { background: #f8f8f8; }
.codehilite .c { color: #3D7B7B; font-style: italic } /* Comment */
.codehilite .err { border: 1px solid #F00 } /* Error */
.codehilite .k { color: #008000; font-weight: bold } /* Keyword */
.codehilite .o { color: #666 } /* Operator */
.codehilite .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
.codehilite .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
.codehilite .cp { color: #9C6500 } /* Comment.Preproc */
.codehilite .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
.codehilite .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
.codehilite .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
.codehilite .gd { color: #A00000 } /* Generic.Deleted */
.codehilite .ge { font-style: italic } /* Generic.Emph */
.codehilite .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */
.codehilite .gr { color: #E40000 } /* Generic.Error */
.codehilite .gh { color: #000080; font-weight: bold } /* Generic.Heading */
.codehilite .gi { color: #008400 } /* Generic.Inserted */
.codehilite .go { color: #717171 } /* Generic.Output */
.codehilite .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
.codehilite .gs { font-weight: bold } /* Generic.Strong */
.codehilite .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
.codehilite .gt { color: #04D } /* Generic.Traceback */
.codehilite .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
.codehilite .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
.codehilite .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
.codehilite .kp { color: #008000 } /* Keyword.Pseudo */
.codehilite .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
.codehilite .kt { color: #B00040 } /* Keyword.Type */
.codehilite .m { color: #666 } /* Literal.Number */
.codehilite .s { color: #BA2121 } /* Literal.String */
.codehilite .na { color: #687822 } /* Name.Attribute */
.codehilite .nb { color: #008000 } /* Name.Builtin */
.codehilite .nc { color: #00F; font-weight: bold } /* Name.Class */
.codehilite .no { color: #800 } /* Name.Constant */
.codehilite .nd { color: #A2F } /* Name.Decorator */
.codehilite .ni { color: #717171; font-weight: bold } /* Name.Entity */
.codehilite .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
.codehilite .nf { color: #00F } /* Name.Function */
.codehilite .nl { color: #767600 } /* Name.Label */
.codehilite .nn { color: #00F; font-weight: bold } /* Name.Namespace */
.codehilite .nt { color: #008000; font-weight: bold } /* Name.Tag */
.codehilite .nv { color: #19177C } /* Name.Variable */
.codehilite .ow { color: #A2F; font-weight: bold } /* Operator.Word */
.codehilite .w { color: #BBB } /* Text.Whitespace */
.codehilite .mb { color: #666 } /* Literal.Number.Bin */
.codehilite .mf { color: #666 } /* Literal.Number.Float */
.codehilite .mh { color: #666 } /* Literal.Number.Hex */
.codehilite .mi { color: #666 } /* Literal.Number.Integer */
.codehilite .mo { color: #666 } /* Literal.Number.Oct */
.codehilite .sa { color: #BA2121 } /* Literal.String.Affix */
.codehilite .sb { color: #BA2121 } /* Literal.String.Backtick */
.codehilite .sc { color: #BA2121 } /* Literal.String.Char */
.codehilite .dl { color: #BA2121 } /* Literal.String.Delimiter */
.codehilite .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
.codehilite .s2 { color: #BA2121 } /* Literal.String.Double */
.codehilite .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
.codehilite .sh { color: #BA2121 } /* Literal.String.Heredoc */
.codehilite .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
.codehilite .sx { color: #008000 } /* Literal.String.Other */
.codehilite .sr { color: #A45A77 } /* Literal.String.Regex */
.codehilite .s1 { color: #BA2121 } /* Literal.String.Single */
.codehilite .ss { color: #19177C } /* Literal.String.Symbol */
.codehilite .bp { color: #008000 } /* Name.Builtin.Pseudo */
.codehilite .fm { color: #00F } /* Name.Function.Magic */
.codehilite .vc { color: #19177C } /* Name.Variable.Class */
.codehilite .vg { color: #19177C } /* Name.Variable.Global */
.codehilite .vi { color: #19177C } /* Name.Variable.Instance */
.codehilite .vm { color: #19177C } /* Name.Variable.Magic */
.codehilite .il { color: #666 } /* Literal.Number.Integer.Long */
  </style>
  <style type="text/css">
/* ==========================================================================
   EXAMPLE Media Queries for Responsive Design.
   These examples override the primary ('mobile first') styles.
   Modify as content requires.
   ========================================================================== */

@media only screen and (min-width: 35em) {
    /* Style adjustments for viewports that meet the condition */
}

@media print,
       (-o-min-device-pixel-ratio: 5/4),
       (-webkit-min-device-pixel-ratio: 1.25),
       (min-resolution: 120dpi) {
    /* Style adjustments for high resolution devices */
}

/* ==========================================================================
   Print styles.
   Inlined to avoid required HTTP connection: h5bp.com/r
   ========================================================================== */

@media print {
    * {
        background: transparent !important;
        color: #000 !important; /* Black prints faster: h5bp.com/s */
        box-shadow: none !important;
        text-shadow: none !important;
    }

    a,
    a:visited {
        text-decoration: underline;
    }

    a[href]:after {
        content: " (" attr(href) ")";
    }

    abbr[title]:after {
        content: " (" attr(title) ")";
    }

    /*
     * Don't show links for images, or javascript/internal links
     */

    .ir a:after,
    a[href^="javascript:"]:after,
    a[href^="#"]:after {
        content: "";
    }

    pre,
    blockquote {
        border: 1px solid #999;
        page-break-inside: avoid;
    }

    thead {
        display: table-header-group; /* h5bp.com/t */
    }

    tr,
    img {
        page-break-inside: avoid;
    }

    img {
        max-width: 100% !important;
    }

    @page {
        margin: 0.5cm;
    }

    p,
    h2,
    h3 {
        orphans: 3;
        widows: 3;
    }

    h2,
    h3 {
        page-break-after: avoid;
    }
}
</style>

  <script type="text/javascript">
  function toggle(id, $link) {
    $node = document.getElementById(id);
    if (!$node)
    return;
    if (!$node.style.display || $node.style.display == 'none') {
    $node.style.display = 'block';
    $link.innerHTML = 'Hide source &nequiv;';
    } else {
    $node.style.display = 'none';
    $link.innerHTML = 'Show source &equiv;';
    }
  }
  </script>
</head>
<body>
<a href="#" id="top">Top</a>
<div id="container">




















  <div id="sidebar">
    <h1>Index</h1>
    <ul id="index">
    <li class="set"><h3>Super-module</h3>
      <ul>
        <li class="mono"><a href="index.html">redxregressors</a></li>
      </ul>
    </li>
    <li class="set"><h3><a href="#header-variables">Module variables</a></h3>

  <ul>
    <li class="mono"><a href="#redxregressors.tune.log">log</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-functions">Functions</a></h3>

  <ul>
    <li class="mono"><a href="#redxregressors.tune.build_param_grid">build_param_grid</a></li>
    <li class="mono"><a href="#redxregressors.tune.layer_size_to_network">layer_size_to_network</a></li>
    <li class="mono"><a href="#redxregressors.tune.objective_defined_train_test_single_rmse">objective_defined_train_test_single_rmse</a></li>
    <li class="mono"><a href="#redxregressors.tune.objective_predefined_cv_multi_rmse__r2__diff_train_test">objective_predefined_cv_multi_rmse__r2__diff_train_test</a></li>
    <li class="mono"><a href="#redxregressors.tune.objective_random_cv_multi_rmse__r2__diff_train_test">objective_random_cv_multi_rmse__r2__diff_train_test</a></li>
    <li class="mono"><a href="#redxregressors.tune.optimize_dnn_arch_and_train">optimize_dnn_arch_and_train</a></li>
    <li class="mono"><a href="#redxregressors.tune.run_kfold_study_with_mlflow">run_kfold_study_with_mlflow</a></li>
    <li class="mono"><a href="#redxregressors.tune.run_train_test_study_with_mlflow">run_train_test_study_with_mlflow</a></li>
  </ul>

    </li>

    <li class="set"><h3><a href="#header-classes">Classes</a></h3>
      <ul>
        <li class="mono">
        <span class="class_name"><a href="#redxregressors.tune.JoinKfoldData">JoinKfoldData</a></span>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#redxregressors.tune.WrappedKNeighbors">WrappedKNeighbors</a></span>


  <ul>
    <li class="mono"><a href="#redxregressors.tune.WrappedKNeighbors.predict">predict</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#redxregressors.tune.build_kfold_objective">build_kfold_objective</a></span>


  <ul>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.parity_plot">parity_plot</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.plot_prediction_error">plot_prediction_error</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.plot_qq">plot_qq</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.plot_residuals">plot_residuals</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.abs_train_test_diff_objective">abs_train_test_diff_objective</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.build_param_grid">build_param_grid</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.get_all_data_as_single_fold">get_all_data_as_single_fold</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.get_data">get_data</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.objectivefx">objectivefx</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_kfold_objective.set_objectives">set_objectives</a></li>
  </ul>

        </li>
        <li class="mono">
        <span class="class_name"><a href="#redxregressors.tune.build_train_test_objective">build_train_test_objective</a></span>


  <ul>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.parity_plot">parity_plot</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.plot_prediction_error">plot_prediction_error</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.plot_qq">plot_qq</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.plot_residuals">plot_residuals</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.abs_train_test_diff_objective">abs_train_test_diff_objective</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.build_param_grid">build_param_grid</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.get_all_data_as_single_set">get_all_data_as_single_set</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.get_data">get_data</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.objectivefx">objectivefx</a></li>
    <li class="mono"><a href="#redxregressors.tune.build_train_test_objective.set_objectives">set_objectives</a></li>
  </ul>

        </li>
      </ul>
    </li>

    </ul>
  </div>

<article id="content">





  <header id="section-intro">
  <h1 class="title"><span class="name">redxregressors.tune</span> module</h1>
  <p>Module for tuning hyper-parameters for a model using Optuna</p>

  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune" class="source">
    <div class="codehilite"><pre><span></span><span class="ch">#!/usr/bin/env python3</span>
<span class="c1"># -*- coding: utf-8 -*-</span>

<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Module for tuning hyper-parameters for a model using Optuna</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">logging</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">pathlib</span><span class="w"> </span><span class="kn">import</span> <span class="n">Path</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">deepchem</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">dc</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">json</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">deepchem.data</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">optuna</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">mlflow</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">typing</span><span class="w"> </span><span class="kn">import</span> <span class="n">Union</span><span class="p">,</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Any</span><span class="p">,</span> <span class="n">List</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">datetime</span><span class="w"> </span><span class="kn">import</span> <span class="n">datetime</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.model_selection</span><span class="w"> </span><span class="kn">import</span> <span class="n">KFold</span><span class="p">,</span> <span class="n">train_test_split</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.metrics</span><span class="w"> </span><span class="kn">import</span> <span class="n">mean_squared_error</span><span class="p">,</span> <span class="n">r2_score</span><span class="p">,</span> <span class="n">root_mean_squared_error</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.pipeline</span><span class="w"> </span><span class="kn">import</span> <span class="n">Pipeline</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">seaborn</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">sns</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">scipy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">dataclasses</span><span class="w"> </span><span class="kn">import</span> <span class="n">dataclass</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">deepchem</span><span class="w"> </span><span class="kn">import</span> <span class="n">data</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">copy</span><span class="w"> </span><span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">redxregressors</span><span class="w"> </span><span class="kn">import</span> <span class="n">deep_net_models</span>


<span class="kn">from</span><span class="w"> </span><span class="nn">redxregressors</span><span class="w"> </span><span class="kn">import</span> <span class="p">(</span>
    <span class="n">classical_ml_models</span><span class="p">,</span>
    <span class="n">ml_featurization</span><span class="p">,</span>
    <span class="n">utilities</span><span class="p">,</span>
    <span class="n">ml_flow_funcs</span><span class="p">,</span>
    <span class="n">applicability_domain</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">log</span> <span class="o">=</span> <span class="n">logging</span><span class="o">.</span><span class="n">getLogger</span><span class="p">(</span><span class="vm">__name__</span><span class="p">)</span>

<span class="n">optuna</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">set_verbosity</span><span class="p">(</span><span class="n">optuna</span><span class="o">.</span><span class="n">logging</span><span class="o">.</span><span class="n">WARNING</span><span class="p">)</span>


<span class="nd">@dataclass</span>
<span class="k">class</span><span class="w"> </span><span class="nc">JoinKfoldData</span><span class="p">:</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>


<span class="k">class</span><span class="w"> </span><span class="nc">build_train_test_objective</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
        <span class="n">train_frac</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_train</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="n">train_frac</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="o">=</span> <span class="n">n_train</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_all_data_as_single_set</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">kf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">List</span><span class="p">[</span>
                <span class="n">Tuple</span><span class="p">[</span>
                    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="p">]</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to get all the data as a single set. It combines te train and test set into a single set. This is useful for training a model on all the data.</span>
<span class="sd">        The returned data is a tuple of the features and target values as numpy ndarrays.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple[np.ndarray, np.ndarray]: The features and target values</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">]])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">]])</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">abs_train_test_diff_objective</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to calculate the difference between the training and test set scores. This is used as a restraining metric to prevent overfitting.</span>
<span class="sd">        Note this is the difference between the mean scores for all other objectives on all folds of the k fold.</span>
<span class="sd">        Args:</span>
<span class="sd">            train_scores (np.ndarray): The training set scores</span>
<span class="sd">            test_scores (np.ndarray): The test set scores</span>
<span class="sd">        Returns:</span>
<span class="sd">            float: The absolute difference between the training and test set scores</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">build_param_grid</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to build the parameter grid for the optimization</span>
<span class="sd">        Args:</span>
<span class="sd">            parameters (dict): The parameters to optimize over</span>
<span class="sd">            trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">            param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.</span>
<span class="sd">        Returns:</span>
<span class="sd">            dict[Any, Any]: The parameter grid</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;catagorical&quot;</span><span class="p">:</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">param_grid</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_test_predefined</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">Tuple</span><span class="p">[</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">train_frac</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">n_train</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Data should be passed in as either lists or tuples containing numpy arrays or pandas dataframes/Series objects to X and y</span>
<span class="sd">        which will be randomly split into k folds or a predefined kfold object can be passed in as kf. The predefined kf should be</span>
<span class="sd">        either a deepchem kfold object or list of tuples of JoinKfoldData classes with X and y being numpy arrays. The data is then</span>
<span class="sd">        stored in the cv_data and cv_ids attributes of the class object.</span>
<span class="sd">        Args:</span>
<span class="sd">            X (Optional[Union[np.ndarray, pd.DataFrame]]): The features</span>
<span class="sd">            y (Optional[Union[np.ndarray, pd.Series]]): The target values</span>
<span class="sd">            kf (Optional[List[Tuple[Union[np.ndarray, data.datasets.DiskDataset], Union[np.ndarray, data.datasets.DiskDataset]]]): The predefined kfold object</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># deal with the case where the data is passed in as numpy arrays or pandas dataframes</span>
        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>

            <span class="c1"># if the train_frac is not set then set it to the default value of 0.8</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_frac</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="c1"># if the n_train is not set then set it to the default value of None and use 0.8 fraction</span>
                <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">n_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;Both the class level train_frac variable and function level train_frac argument are set to None, the train_frac will be set to the default value of 0.8&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="mf">0.8</span>
                <span class="k">elif</span> <span class="n">n_train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="o">=</span> <span class="n">n_train</span>

            <span class="k">elif</span> <span class="n">train_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="n">train_frac</span>

            <span class="c1"># if the train_frac is set then split the data into a training and test set</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="p">,</span>
                    <span class="n">train_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>

            <span class="c1"># if the n_train is set then split the data into a training and test set</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                    <span class="n">X</span><span class="p">,</span>
                    <span class="n">y</span><span class="p">,</span>
                    <span class="n">train_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_train</span><span class="p">,</span>
                    <span class="n">random_state</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                    <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>

        <span class="c1"># deal with the case where the data is passed in as a predefined train test split</span>
        <span class="k">elif</span> <span class="n">train_test_predefined</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="c1"># if the train_test_predefined is a deepchem object then set the train and test attributes</span>
                <span class="k">if</span> <span class="s2">&quot;deepchem&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span>
                        <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">y</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span>
                        <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">y</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
                    <span class="p">)</span>

                <span class="c1"># if the train_test_predefined is a list of tuples of numpy arrays then set the train and test attributes</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="c1"># if the train_test_predefined is a JoinKfoldData object then set the train and test attributes</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">JoinKfoldData</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                                <span class="p">],</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;test_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                                <span class="p">],</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                    <span class="c1"># if the train_test_predefined is a list of tuples of numpy arrays then set the train and test attributes</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="s2">&quot;The train_test_predefined do not have a deepchem or JoinKfoldData object format will try to format&quot;</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span>
                            <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="p">(</span>
                            <span class="n">JoinKfoldData</span><span class="p">(</span>
                                <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                                <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                            <span class="p">),</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
                                <span class="p">],</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;test_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
                                <span class="p">],</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
            <span class="c1"># if the train_test_predefined is not in the correct format then raise an error</span>
            <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;The train_test_predefined object is not in the correct format, it should be either a deepchem data object or a list of tuples of numpy arrays&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_objectives</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">objectives</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">directions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_train_test_diff_objective</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the objectives and directions for the optimization. These should be metrics with an interface of objective = func(y_true, y_pred) and direction to be one of [&quot;minimize&quot;, &quot;maximize&quot;].</span>
<span class="sd">        If add_train_test_diff_objective is set to True the difference between the training and test set scores will be added as an objective to minimize. This provides a restraining metric to prevent overfitting.</span>
<span class="sd">        Args:</span>
<span class="sd">            objectives (Optional[List[Callable]]): A list of objective functions to optimize</span>
<span class="sd">            directions (Optional[List[str]]): A list of directions to optimize the objectives in</span>
<span class="sd">            add_train_test_diff_objective (bool): Whether to add a restraining metric to prevent overfitting</span>
<span class="sd">        Returns:</span>
<span class="sd">            List[str]: A list of directions to optimize the objectives</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">objectives</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="p">[</span><span class="n">root_mean_squared_error</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="n">objectives</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="n">directions</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="o">=</span> <span class="n">add_train_test_diff_objective</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After adding </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span><span class="p">)</span>

    <span class="c1"># Make the plotting functions static methods so they can be used without an instance of the class</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">parity_plot</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">xymin</span><span class="p">,</span>
        <span class="n">xymax</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the parity plot of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (JoinKfoldData): The test set data</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            xymin (float): The minimum value for the x and y axis</span>
<span class="sd">            xymax (float): The maximum value for the x and y axis</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">        Returns:</span>
<span class="sd">            plt.Figure: The parity plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Least squares regression line</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">deg</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">xseq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

        <span class="c1"># plot the parity plot figure</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">y_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prefect Prediction&quot;</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;#89a0b0&quot;</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="p">[</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;x = y&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                <span class="n">xseq</span><span class="p">,</span> <span class="n">m</span> <span class="o">*</span> <span class="n">xseq</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="s2">&quot;m-.&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Least Squares Regression Line&quot;</span>
            <span class="p">)</span>  <span class="c1"># y = mx + c</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">y_test</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Model predictions RMSE: </span><span class="si">{</span><span class="n">root_mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> R2 Coefficent of determination </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Experimental&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test Set Experimental Vs. Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_residuals</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the residuals of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (np.ndarray): The test set target values</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>

<span class="sd">        Returns:</span>
<span class="sd">            plt.figure: The residuals plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">sns</span><span class="o">.</span><span class="n">residplot</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">lowess</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;lw&quot;</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">},</span>
            <span class="p">)</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Residual Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_prediction_error</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the prediction error plot of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (np.ndarray): The test set target values</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            style (str): The style of the plot</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>

<span class="sd">        Returns:</span>
<span class="sd">            plt.Figure: The prediction error plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Error Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predictions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Errors&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_qq</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the QQ plot of the residuals of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (np.ndarray): The test set target values</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            style (str): The style of the plot</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">        Returns:</span>
<span class="sd">            plt.Figure: The QQ plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LOOK: </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;QQ Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Theoretical Quantiles&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Ordered Values&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
                <span class="k">return</span> <span class="kc">None</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">objectivefx</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
        <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;kfold_study&quot;</span><span class="p">,</span>
        <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">without_mlflow</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.</span>
<span class="sd">        It should be used like:</span>

<span class="sd">        ```python</span>

<span class="sd">        cls = build_kfold_objective(&quot;test&quot;, 5)</span>
<span class="sd">        cls.get_data(X, y)</span>
<span class="sd">        directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])</span>

<span class="sd">        experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)</span>

<span class="sd">        pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])</span>

<span class="sd">        study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f&#39;sqlite:///test.db&#39;, load_if_exists=True)</span>

<span class="sd">        func = lambda trial: cls.objectivefx(</span>
<span class="sd">            trial,</span>
<span class="sd">            pipe,</span>
<span class="sd">            priors,</span>
<span class="sd">            name=&quot;kfold_run&quot;,</span>
<span class="sd">            experiment_id=experiment_id</span>
<span class="sd">        )</span>

<span class="sd">        study.optimize(</span>
<span class="sd">            func,</span>
<span class="sd">            n_trials=40,</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">            trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">            regressorfx (Any): The regressor function to optimize</span>
<span class="sd">            parameters (dict): The parameter grid to optimize over</span>
<span class="sd">            update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.</span>
<span class="sd">            name (Optional[str], optional): The name of the study. Defaults to &quot;kfold_study&quot;.</span>
<span class="sd">            experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.</span>
<span class="sd">            experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">without_mlflow</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;Training without MLFlow&quot;</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_without_mlflow</span><span class="p">(</span>
                <span class="n">trial</span><span class="p">,</span>
                <span class="n">regressorfx</span><span class="p">,</span>
                <span class="n">parameters</span><span class="p">,</span>
                <span class="n">update_param_grid_callback</span><span class="p">,</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;Training with MLFlow&quot;</span><span class="p">)</span>
            <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_with_mlflow</span><span class="p">(</span>
                <span class="n">trial</span><span class="p">,</span>
                <span class="n">regressorfx</span><span class="p">,</span>
                <span class="n">parameters</span><span class="p">,</span>
                <span class="n">update_param_grid_callback</span><span class="p">,</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">experiment_id</span><span class="p">,</span>
                <span class="n">experiment_description</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">return</span> <span class="n">scores</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_objectivefx_without_mlflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
        <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;tt_study&quot;</span><span class="p">,</span>
        <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.</span>
<span class="sd">        It should be used like:</span>

<span class="sd">        ```python</span>

<span class="sd">        cls = build_kfold_objective(&quot;test&quot;, 5)</span>
<span class="sd">        cls.get_data(X, y)</span>
<span class="sd">        directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])</span>

<span class="sd">        experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)</span>

<span class="sd">        pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])</span>

<span class="sd">        study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f&#39;sqlite:///test.db&#39;, load_if_exists=True)</span>

<span class="sd">        func = lambda trial: cls.objectivefx(</span>
<span class="sd">            trial,</span>
<span class="sd">            pipe,</span>
<span class="sd">            priors,</span>
<span class="sd">            name=&quot;kfold_run&quot;,</span>
<span class="sd">            experiment_id=experiment_id</span>
<span class="sd">        )</span>

<span class="sd">        study.optimize(</span>
<span class="sd">            func,</span>
<span class="sd">            n_trials=40,</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">            trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">            regressorfx (Any): The regressor function to optimize</span>
<span class="sd">            parameters (dict): The parameter grid to optimize over</span>
<span class="sd">            update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.</span>
<span class="sd">            name (Optional[str], optional): The name of the study. Defaults to &quot;kfold_study&quot;.</span>
<span class="sd">            experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">ptrain</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train-test-training/train-</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">trial</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ptrain</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">ptest</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Train-test-training/test-</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">trial</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ptest</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># get the parameter grid</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">ptrain</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;param_grid.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">jout</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">jout</span><span class="p">)</span>

        <span class="c1"># update the parameter grid if a callback is provided</span>
        <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span>
                <span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="c1"># set variables for the training scores to be saved per call</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_scores</span><span class="p">)</span>

        <span class="c1"># run the model trianing</span>
        <span class="c1"># set the regressor with the parameters</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

        <span class="c1"># fit the model</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

        <span class="c1"># get the training set predcition scores</span>
        <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;Training set objective [</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">]: </span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> Train scores shape: </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
            <span class="p">)</span>
            <span class="n">train_scores</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores data frame </span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores means </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">t_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="p">[</span><span class="n">train_scores</span><span class="p">],</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
            <span class="p">)</span>
            <span class="n">t_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">ptrain</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;train_scores.csv&quot;</span><span class="p">))</span>

        <span class="c1"># get the test set predictions</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
            <span class="n">test_scores</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

        <span class="c1"># plot the parity plot of the predictions</span>
        <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
        <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">xymin</span><span class="p">,</span>
            <span class="n">xymax</span><span class="p">,</span>
            <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span>
                    <span class="s2">&quot;internal_test_set_parity_plot_train_test.png&quot;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span>
                    <span class="s2">&quot;internal_test_set_residual_plot_train_test.png&quot;</span>
                <span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;internal_test_set_error_plot_train_test.png&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;internal_test_set_qq_plot_train_test.png&quot;</span><span class="p">))</span>
        <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;internal_test_set_qq_plot_train_test.png&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
            <span class="p">),</span>
        <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Experiment to train an scikit-learn pipeline defined as: &quot;</span>
                <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">regressor</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
                <span class="o">+</span> <span class="s2">&quot;. &quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">description</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Experiment to train a model </span><span class="si">{</span><span class="n">regressorfx</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> model with parameters: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">}</span><span class="s2">. &quot;</span>

        <span class="k">if</span> <span class="n">experiment_description</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">description</span> <span class="o">+=</span> <span class="n">experiment_description</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">ptrain</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;description.txt&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
            <span class="n">fout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>

        <span class="c1"># Log to MLflow the parameters and the objective values</span>
        <span class="k">for</span> <span class="n">xth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
        <span class="n">tt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">[</span><span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">],</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;test&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">tt_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;train_test_scores.csv&quot;</span><span class="p">))</span>

        <span class="c1"># add the absolute difference between the training and test set scores as an objective if requested then return the scores</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">abs_train_test_diff_objective</span><span class="p">(</span>
                <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="o">*</span><span class="n">test_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">train_val_abs_diff</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_objectivefx_with_mlflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
        <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;tt_study&quot;</span><span class="p">,</span>
        <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.</span>
<span class="sd">        It should be used like:</span>

<span class="sd">        ```python</span>

<span class="sd">        cls = build_kfold_objective(&quot;test&quot;, 5)</span>
<span class="sd">        cls.get_data(X, y)</span>
<span class="sd">        directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])</span>

<span class="sd">        experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)</span>

<span class="sd">        pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])</span>

<span class="sd">        study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f&#39;sqlite:///test.db&#39;, load_if_exists=True)</span>

<span class="sd">        func = lambda trial: cls.objectivefx(</span>
<span class="sd">            trial,</span>
<span class="sd">            pipe,</span>
<span class="sd">            priors,</span>
<span class="sd">            name=&quot;kfold_run&quot;,</span>
<span class="sd">            experiment_id=experiment_id</span>
<span class="sd">        )</span>

<span class="sd">        study.optimize(</span>
<span class="sd">            func,</span>
<span class="sd">            n_trials=40,</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">            trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">            regressorfx (Any): The regressor function to optimize</span>
<span class="sd">            parameters (dict): The parameter grid to optimize over</span>
<span class="sd">            update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.</span>
<span class="sd">            name (Optional[str], optional): The name of the study. Defaults to &quot;kfold_study&quot;.</span>
<span class="sd">            experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.</span>
<span class="sd">            experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Train-</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">trial</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># get the parameter grid</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>

            <span class="c1"># update the parameter grid if a callback is provided</span>
            <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span>
                    <span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span>
                <span class="p">)</span>

            <span class="c1"># set variables for the training scores to be saved per call</span>
            <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
            <span class="n">test_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>

            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_scores</span><span class="p">)</span>

            <span class="c1"># run the model trianing</span>
            <span class="c1"># set the regressor with the parameters</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
                <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

            <span class="c1"># fit the model</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

            <span class="c1"># get the training set predcition scores</span>
            <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Training set objective [</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">]: </span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> Train scores shape: </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">train_scores</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores data frame </span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores means </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="c1"># get the test set predictions</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                <span class="n">test_scores</span><span class="p">[</span><span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

            <span class="c1"># plot the parity plot of the predictions</span>
            <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">parity_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">xymin</span><span class="p">,</span>
                <span class="n">xymax</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                <span class="n">parity_plt</span><span class="p">,</span> <span class="s2">&quot;internal_test_set_parity_plot_train_test.png&quot;</span>
            <span class="p">)</span>
            <span class="n">residual_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                <span class="n">residual_plt</span><span class="p">,</span> <span class="s2">&quot;internal_test_set_residual_plot_train_test.png&quot;</span>
            <span class="p">)</span>
            <span class="n">err_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span><span class="n">err_plt</span><span class="p">,</span> <span class="s2">&quot;internal_test_set_error_plot_train_test.png&quot;</span><span class="p">)</span>
            <span class="n">qq_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span><span class="n">qq_plt</span><span class="p">,</span> <span class="s2">&quot;internal_test_set_qq_plot_train_test.png&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
                <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;Experiment to train an scikit-learn pipeline defined as: &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">regressor</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
                    <span class="o">+</span> <span class="s2">&quot;. &quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">description</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Experiment to train a model </span><span class="si">{</span><span class="n">regressorfx</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> model with parameters: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">}</span><span class="s2">. &quot;</span>

            <span class="k">if</span> <span class="n">experiment_description</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="n">experiment_description</span>

            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_text</span><span class="p">(</span><span class="n">description</span><span class="p">,</span> <span class="s2">&quot;description.txt&quot;</span><span class="p">)</span>

            <span class="c1"># Log to MLflow the parameters and the objective values</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">xth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_train&quot;</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_test&quot;</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>

            <span class="c1"># add the absolute difference between the training and test set scores as an objective if requested then return the scores</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">abs_train_test_diff_objective</span><span class="p">(</span>
                    <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="o">*</span><span class="n">test_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">train_val_abs_diff</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>


<span class="k">class</span><span class="w"> </span><span class="nc">build_kfold_objective</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">k</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">k</span> <span class="o">=</span> <span class="n">k</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_all_data_as_single_fold</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">kf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">List</span><span class="p">[</span>
                <span class="n">Tuple</span><span class="p">[</span>
                    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="p">]</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to get all the data as a single fold. It combines each test set from the k fold into a single set. This is useful for training a model on all the data.</span>
<span class="sd">        The returned data is a tuple of the features and target values as numpy.</span>
<span class="sd">        Returns:</span>
<span class="sd">            Tuple[np.ndarray, np.ndarray]: The features and target values</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">kf</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="p">])</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">])</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">abs_train_test_diff_objective</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to calculate the difference between the training and test set scores. This is used as a restraining metric to prevent overfitting.</span>
<span class="sd">        Note this is the difference between the mean scores for all other objectives on all folds of the k fold.</span>
<span class="sd">        Args:</span>
<span class="sd">            train_scores (np.ndarray): The training set scores</span>
<span class="sd">            test_scores (np.ndarray): The test set scores</span>
<span class="sd">        Returns:</span>
<span class="sd">            float: The absolute difference between the training and test set scores</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">build_param_grid</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to build the parameter grid for the optimization</span>
<span class="sd">        Args:</span>
<span class="sd">            parameters (dict): The parameters to optimize over</span>
<span class="sd">            trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">            param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.</span>
<span class="sd">        Returns:</span>
<span class="sd">            dict[Any, Any]: The parameter grid</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>

        <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="k">elif</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
            <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;catagorical&quot;</span><span class="p">:</span>
                <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

        <span class="k">return</span> <span class="n">param_grid</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">get_data</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">kf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
            <span class="n">List</span><span class="p">[</span>
                <span class="n">Tuple</span><span class="p">[</span>
                    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="p">]</span>
            <span class="p">]</span>
        <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Data should be passed in as either lists or tuples containing numpy arrays or pandas dataframes/Series objects to X and y</span>
<span class="sd">        which will be randomly split into k folds or a predefined kfold object can be passed in as kf. The predefined kf should be</span>
<span class="sd">        either a deepchem kfold object or list of tuples of JoinKfoldData classes with X and y being numpy arrays. The data is then</span>
<span class="sd">        stored in the cv_data and cv_ids attributes of the class object.</span>
<span class="sd">        Args:</span>
<span class="sd">            X (Optional[Union[np.ndarray, pd.DataFrame]]): The features</span>
<span class="sd">            y (Optional[Union[np.ndarray, pd.Series]]): The target values</span>
<span class="sd">            kf (Optional[List[Tuple[Union[np.ndarray, data.datasets.DiskDataset], Union[np.ndarray, data.datasets.DiskDataset]]]): The predefined kfold object</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>

            <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">train_indx</span><span class="p">,</span> <span class="n">test_indx</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">(</span>
                        <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">train_indx</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">train_indx</span><span class="p">]),</span>
                        <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">test_indx</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">test_indx</span><span class="p">]),</span>
                    <span class="p">)</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">train_indx</span><span class="p">,</span> <span class="n">test_indx</span><span class="p">))</span>

        <span class="k">elif</span> <span class="n">kf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">try</span><span class="p">:</span>
                <span class="k">if</span> <span class="s2">&quot;deepchem&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">kf</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])):</span>
                    <span class="k">for</span> <span class="n">trainf</span><span class="p">,</span> <span class="n">testf</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">:</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">trainf</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">trainf</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                                <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">testf</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">testf</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">trainf</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">testf</span><span class="o">.</span><span class="n">ids</span><span class="p">))</span>

                <span class="k">else</span><span class="p">:</span>
                    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kf</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">JoinKfoldData</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span> <span class="o">=</span> <span class="n">kf</span>
                        <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">trainf</span><span class="p">,</span> <span class="n">testf</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="p">(</span>
                                    <span class="p">[</span>
                                        <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                        <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainf</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                                    <span class="p">],</span>
                                    <span class="p">[</span>
                                        <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_testrow_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                        <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testf</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                                    <span class="p">],</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                    <span class="k">else</span><span class="p">:</span>
                        <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                            <span class="s2">&quot;The kfolds do not have a deepchem or JoinKfoldData object format will try to format&quot;</span>
                        <span class="p">)</span>
                        <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">trainf</span><span class="p">,</span> <span class="n">testf</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="p">(</span>
                                    <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">trainf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">trainf</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                    <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">testf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">testf</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                                <span class="p">(</span>
                                    <span class="p">[</span>
                                        <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                        <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainf</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                                    <span class="p">],</span>
                                    <span class="p">[</span>
                                        <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_testrow_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                        <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testf</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                                    <span class="p">],</span>
                                <span class="p">)</span>
                            <span class="p">)</span>
            <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                    <span class="s2">&quot;The kfolds object is not in the correct format, it should be either a deepchem kfold data object or a list of tuples of numpy arrays&quot;</span>
                <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">set_objectives</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">objectives</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">directions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">add_train_test_diff_objective</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set the objectives and directions for the optimization. These should be metrics with an interface of objective = func(y_true, y_pred) and direction to be one of [&quot;minimize&quot;, &quot;maximize&quot;].</span>
<span class="sd">        If add_train_test_diff_objective is set to True the difference between the training and test set scores will be added as an objective to minimize. This provides a restraining metric to prevent overfitting.</span>
<span class="sd">        Args:</span>
<span class="sd">            objectives (Optional[List[Callable]]): A list of objective functions to optimize</span>
<span class="sd">            directions (Optional[List[str]]): A list of directions to optimize the objectives in</span>
<span class="sd">            add_train_test_diff_objective (bool): Whether to add a restraining metric to prevent overfitting</span>
<span class="sd">        Returns:</span>
<span class="sd">            List[str]: A list of directions to optimize the objectives</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">objectives</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="p">[</span><span class="n">root_mean_squared_error</span><span class="p">]</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="n">objectives</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="n">directions</span>

        <span class="c1"># self.objective_values = [np.zeros(self.k) for _ in range(len(self.objectives))]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)]</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="o">=</span> <span class="n">add_train_test_diff_objective</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="c1"># log.debug(&quot;LOOK HERE: ADDED TRAIN TEST DIFF OBJECTIVE&quot;)</span>
            <span class="c1"># log.debug(f&quot;Before adding {self.objective_values}&quot;)</span>
            <span class="c1"># self.objective_values = np.array(</span>
            <span class="c1">#     [np.append(ent, [0.0]) for ent in self.objective_values]</span>
            <span class="c1"># )</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After adding </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="c1"># self.objectives += [self.abs_train_test_diff_objective]</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">])</span>

        <span class="k">else</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Not added train test diff objective as requested&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span><span class="p">)</span>

    <span class="c1"># Make the plotting functions static methods so they can be used without an instance of the class</span>
    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">parity_plot</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">xymin</span><span class="p">,</span>
        <span class="n">xymax</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the parity plot of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (JoinKfoldData): The test set data</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            xymin (float): The minimum value for the x and y axis</span>
<span class="sd">            xymax (float): The maximum value for the x and y axis</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>

<span class="sd">        Returns:</span>
<span class="sd">            plt.Figure: The parity plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="c1"># Least squares regression line</span>
        <span class="n">m</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">deg</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">xseq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

        <span class="c1"># plot the parity plot figure</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">y_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prefect Prediction&quot;</span><span class="p">,</span>
                <span class="n">c</span><span class="o">=</span><span class="s2">&quot;#89a0b0&quot;</span><span class="p">,</span>
                <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="p">[</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;x = y&quot;</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
                <span class="n">xseq</span><span class="p">,</span> <span class="n">m</span> <span class="o">*</span> <span class="n">xseq</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="s2">&quot;m-.&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Least Squares Regression Line&quot;</span>
            <span class="p">)</span>  <span class="c1"># y = mx + c</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
                <span class="n">y_test</span><span class="p">,</span>
                <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Model predictions RMSE: </span><span class="si">{</span><span class="n">root_mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> R2 Coefficent of determination </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Experimental&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test Set Experimental Vs. Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_residuals</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the residuals of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (np.ndarray): The test set target values</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>

<span class="sd">        Returns:</span>
<span class="sd">            plt.figure: The residuals plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">sns</span><span class="o">.</span><span class="n">residplot</span><span class="p">(</span>
                <span class="n">x</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
                <span class="n">y</span><span class="o">=</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">lowess</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
                <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;lw&quot;</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">},</span>
            <span class="p">)</span>

            <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Residual Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">fig</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_prediction_error</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the prediction error plot of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (np.ndarray): The test set target values</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            style (str): The style of the plot</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>

<span class="sd">        Returns:</span>
<span class="sd">            plt.Figure: The prediction error plot</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Error Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predictions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Errors&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span><span class="w"> </span><span class="nf">plot_qq</span><span class="p">(</span>
        <span class="n">y_test</span><span class="p">,</span>
        <span class="n">y_pred</span><span class="p">,</span>
        <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
        <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
        <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
        <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to plot the QQ plot of the residuals of the test set predictions</span>
<span class="sd">        Args:</span>
<span class="sd">            y_test (np.ndarray): The test set target values</span>
<span class="sd">            y_pred (np.ndarray): The predicted values</span>
<span class="sd">            style (str): The style of the plot</span>
<span class="sd">            size (Tuple[int, int]): The size of the plot</span>
<span class="sd">            title_fontsize (int): The fontsize of the title</span>
<span class="sd">            fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">        Returns:</span>
<span class="sd">            plt.Figure: The QQ plot</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
            <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
            <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;QQ Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Theoretical Quantiles&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Ordered Values&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
            <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
                <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>

        <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fig</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">objectivefx</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
        <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;kfold_study&quot;</span><span class="p">,</span>
        <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">without_mlflow</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
    <span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.</span>
<span class="sd">        It should be used like:</span>

<span class="sd">        ```python</span>

<span class="sd">        cls = build_kfold_objective(&quot;test&quot;, 5)</span>
<span class="sd">        cls.get_data(X, y)</span>
<span class="sd">        directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])</span>

<span class="sd">        experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)</span>

<span class="sd">        pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])</span>

<span class="sd">        study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f&#39;sqlite:///test.db&#39;, load_if_exists=True)</span>

<span class="sd">        func = lambda trial: cls.objectivefx(</span>
<span class="sd">            trial,</span>
<span class="sd">            pipe,</span>
<span class="sd">            priors,</span>
<span class="sd">            name=&quot;kfold_run&quot;,</span>
<span class="sd">            experiment_id=experiment_id</span>
<span class="sd">        )</span>

<span class="sd">        study.optimize(</span>
<span class="sd">            func,</span>
<span class="sd">            n_trials=40,</span>
<span class="sd">        )</span>
<span class="sd">        ```</span>

<span class="sd">        Args:</span>
<span class="sd">            trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">            regressorfx (Any): The regressor function to optimize</span>
<span class="sd">            parameters (dict): The parameter grid to optimize over</span>
<span class="sd">            update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.</span>
<span class="sd">            name (Optional[str], optional): The name of the study. Defaults to &quot;kfold_study&quot;.</span>
<span class="sd">            experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.</span>
<span class="sd">            experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</span>
<span class="sd">            with_mlflow (bool): Whether to use mlflow or not</span>

<span class="sd">        Returns:</span>
<span class="sd">            Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="n">without_mlflow</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_with_mlflow</span><span class="p">(</span>
                <span class="n">trial</span><span class="p">,</span>
                <span class="n">regressorfx</span><span class="p">,</span>
                <span class="n">parameters</span><span class="p">,</span>
                <span class="n">update_param_grid_callback</span><span class="p">,</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">experiment_id</span><span class="p">,</span>
                <span class="n">experiment_description</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_without_mlflow</span><span class="p">(</span>
                <span class="n">trial</span><span class="p">,</span>
                <span class="n">regressorfx</span><span class="p">,</span>
                <span class="n">parameters</span><span class="p">,</span>
                <span class="n">update_param_grid_callback</span><span class="p">,</span>
                <span class="n">name</span><span class="p">,</span>
                <span class="n">experiment_description</span><span class="p">,</span>
                <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
            <span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_objectivefx_with_mlflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
        <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;kfold_study&quot;</span><span class="p">,</span>
        <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
    <span class="p">]:</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Train-</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">trial</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># get the parameter grid</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>

            <span class="c1"># update the parameter grid if a callback is provided</span>
            <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span>
                    <span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span>
                <span class="p">)</span>

            <span class="c1"># set variables for the training scores to be saved per call</span>
            <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
            <span class="n">test_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>

            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_scores</span><span class="p">)</span>

            <span class="c1"># run the cross validation folds</span>
            <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="p">):</span>
                <span class="c1"># set the regressor with the parameters</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
                    <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

                <span class="c1"># fit the model</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

                <span class="c1"># get the training set predcition scores</span>
                <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Training set objective [</span><span class="si">{</span><span class="n">ith</span><span class="si">}{</span><span class="n">jth</span><span class="si">}</span><span class="s2">]: </span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> Train scores shape: </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="n">train_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">,</span> <span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;Training scores data frame </span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>
                    <span class="p">)</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores means </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

                <span class="c1"># get the test set predictions</span>
                <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

                <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                    <span class="n">test_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">,</span> <span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

                <span class="c1"># plot the parity plot of the predictions</span>
                <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
                <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">parity_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">parity_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;internal_test_set_parity_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>
                <span class="n">residual_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">residual_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;internal_test_set_residual_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>
                <span class="n">err_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">err_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;internal_test_set_error_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>
                <span class="n">qq_plt</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span><span class="n">qq_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;internal_test_set_qq_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>

            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
                <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
                    <span class="s2">&quot;Experiment to train an scikit-learn pipeline defined as: &quot;</span>
                    <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">regressor</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
                    <span class="o">+</span> <span class="s2">&quot;. &quot;</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">description</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Experiment to train a model </span><span class="si">{</span><span class="n">regressorfx</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> model with parameters: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">}</span><span class="s2">. &quot;</span>

            <span class="k">if</span> <span class="n">experiment_description</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">description</span> <span class="o">+=</span> <span class="n">experiment_description</span>

            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_text</span><span class="p">(</span><span class="n">description</span><span class="p">,</span> <span class="s2">&quot;description.txt&quot;</span><span class="p">)</span>

            <span class="c1"># get the mean scores for the cross validation</span>
            <span class="n">train_cv_scores</span> <span class="o">=</span> <span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">test_cv_scores</span> <span class="o">=</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">train_cv_scores_std</span> <span class="o">=</span> <span class="n">train_scores</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
            <span class="n">test_cv_scores_std</span> <span class="o">=</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

            <span class="c1"># Log to MLflow the parameters and the objective values</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_params</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">xth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_cv_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_cv_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_train&quot;</span><span class="p">,</span> <span class="n">train_cv_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_test&quot;</span><span class="p">,</span> <span class="n">test_cv_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_std_train&quot;</span><span class="p">,</span> <span class="n">train_cv_scores_std</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">_std_test&quot;</span><span class="p">,</span> <span class="n">test_cv_scores_std</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>

            <span class="c1"># add the absolute difference between the training and test set scores as an objective if requested then return the scores</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">abs_train_test_diff_objective</span><span class="p">(</span>
                    <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span>
                <span class="p">)</span>
                <span class="k">return</span> <span class="o">*</span><span class="n">test_cv_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">train_val_abs_diff</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">return</span> <span class="n">test_cv_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_objectivefx_without_mlflow</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
        <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
        <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;kfold_study&quot;</span><span class="p">,</span>
        <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
        <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
    <span class="p">]:</span>
        <span class="n">ptrain</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kfold-training/train-</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">trial</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ptrain</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">ptest</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Kfold-training/test-</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">trial</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">ptest</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># get the parameter grid</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">ptrain</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;param_grid.json&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">jout</span><span class="p">:</span>
            <span class="n">json</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">param_grid</span><span class="p">,</span> <span class="n">jout</span><span class="p">)</span>

        <span class="c1"># update the parameter grid if a callback is provided</span>
        <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span>
                <span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span>
            <span class="p">)</span>

        <span class="c1"># set variables for the training scores to be saved per call</span>
        <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
        <span class="n">test_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_scores</span><span class="p">)</span>

        <span class="c1"># run the cross validation folds</span>
        <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="p">):</span>
            <span class="c1"># set the regressor with the parameters</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
                <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

            <span class="c1"># fit the model</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>

            <span class="c1"># get the training set predcition scores</span>
            <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Training set objective [</span><span class="si">{</span><span class="n">ith</span><span class="si">}{</span><span class="n">jth</span><span class="si">}</span><span class="s2">]: </span><span class="si">{</span><span class="n">obj</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> Train scores shape: </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">shape</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>
                <span class="n">train_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">,</span> <span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores data frame </span><span class="si">{</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training scores means </span><span class="si">{</span><span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

            <span class="n">t_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">train_scores</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;train_</span><span class="si">{</span><span class="n">xth</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">xth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)],</span>
            <span class="p">)</span>
            <span class="n">t_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">ptrain</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;train_scores.csv&quot;</span><span class="p">))</span>

            <span class="c1"># get the test set predictions</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

            <span class="k">for</span> <span class="n">jth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
                <span class="n">test_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">,</span> <span class="n">jth</span><span class="p">]</span> <span class="o">=</span> <span class="n">obj</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>

            <span class="n">test_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">test_scores</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;test_</span><span class="si">{</span><span class="n">xth</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">xth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)],</span>
            <span class="p">)</span>
            <span class="n">test_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;test_scores.csv&quot;</span><span class="p">))</span>

            <span class="c1"># plot the parity plot of the predictions</span>
            <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span><span class="nb">max</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">y_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">()))</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
                <span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">xymin</span><span class="p">,</span>
                <span class="n">xymax</span><span class="p">,</span>
                <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                    <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;internal_test_set_parity_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
                <span class="p">),</span>
            <span class="p">)</span>

            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span>
                <span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                    <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;internal_test_set_residual_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
                <span class="p">),</span>
            <span class="p">)</span>

            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span>
                <span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                    <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;internal_test_set_error_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
                <span class="p">),</span>
            <span class="p">)</span>

            <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span>
                <span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="n">y_pred</span><span class="p">,</span>
                <span class="n">fname</span><span class="o">=</span><span class="nb">str</span><span class="p">(</span>
                    <span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span>
                        <span class="sa">f</span><span class="s2">&quot;internal_test_set_qq_plot_fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">.png&quot;</span>
                    <span class="p">)</span><span class="o">.</span><span class="n">absolute</span><span class="p">()</span>
                <span class="p">),</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">description</span> <span class="o">=</span> <span class="p">(</span>
                <span class="s2">&quot;Experiment to train an scikit-learn pipeline defined as: &quot;</span>
                <span class="o">+</span> <span class="s2">&quot; &quot;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">regressor</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">items</span><span class="p">()])</span>
                <span class="o">+</span> <span class="s2">&quot;. &quot;</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">description</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;Experiment to train a model </span><span class="si">{</span><span class="n">regressorfx</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> model with parameters: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">}</span><span class="s2">. &quot;</span>

        <span class="k">if</span> <span class="n">experiment_description</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">description</span> <span class="o">+=</span> <span class="n">experiment_description</span>

        <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">ptrain</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;description.txt&quot;</span><span class="p">),</span> <span class="s2">&quot;w&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">fout</span><span class="p">:</span>
            <span class="n">fout</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">description</span><span class="p">)</span>

        <span class="c1"># get the mean scores for the cross validation</span>
        <span class="n">train_cv_scores</span> <span class="o">=</span> <span class="n">train_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">test_cv_scores</span> <span class="o">=</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">train_cv_scores_std</span> <span class="o">=</span> <span class="n">train_scores</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">test_cv_scores_std</span> <span class="o">=</span> <span class="n">test_scores</span><span class="o">.</span><span class="n">std</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">xth</span><span class="p">,</span> <span class="n">obj</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">train_cv_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">test_cv_scores</span><span class="p">[</span><span class="n">xth</span><span class="p">])</span>

        <span class="n">tt_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
            <span class="p">[</span><span class="n">train_cv_scores</span><span class="p">,</span> <span class="n">train_cv_scores_std</span><span class="p">,</span> <span class="n">test_cv_scores</span><span class="p">,</span> <span class="n">test_cv_scores_std</span><span class="p">],</span>
            <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">metric</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">metric</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
            <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;train mean&quot;</span><span class="p">,</span> <span class="s2">&quot;train std dev&quot;</span><span class="p">,</span> <span class="s2">&quot;test mean&quot;</span><span class="p">,</span> <span class="s2">&quot;test std dev&quot;</span><span class="p">],</span>
        <span class="p">)</span>
        <span class="n">tt_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="n">ptest</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="s2">&quot;train_test_scores.csv&quot;</span><span class="p">))</span>

        <span class="c1"># add the absolute difference between the training and test set scores as an objective if requested then return the scores</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
            <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">abs_train_test_diff_objective</span><span class="p">(</span>
                <span class="n">train_scores</span><span class="p">,</span> <span class="n">test_scores</span>
            <span class="p">)</span>
            <span class="k">return</span> <span class="o">*</span><span class="n">test_cv_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">(),</span> <span class="n">train_val_abs_diff</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">test_cv_scores</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>


<span class="k">class</span><span class="w"> </span><span class="nc">WrappedKNeighbors</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">model</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
        <span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">distances</span>


<span class="k">def</span><span class="w"> </span><span class="nf">optimize_dnn_arch_and_train</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">assay_targets</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">decreasing_neurons_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">uncertainty</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">fit_transformers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">trans</span><span class="o">.</span><span class="n">Transformer</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_set</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_loader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valid_set</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_loader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_set</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_loader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">smiles_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
            <span class="s2">&quot;n_neurons&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
            <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="c1"># Ensures all the expected keys are present in the parameters dictionary</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">default_parameters</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
            <span class="s2">&quot;n_neurons&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
            <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">}</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span>
        <span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">,</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">activation_funcs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">drop_out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ith</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">decreasing_neurons_only</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">ith</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">layer_sizes</span> <span class="o">/</span> <span class="mi">10</span><span class="p">),</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">layer_sizes</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>

        <span class="n">layer_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_neurons_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">))</span>
        <span class="n">activation_funcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;activation_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">drop_out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dropout_rate_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer_sizes</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">activation_funcs</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">drop_out</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter grid: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_set</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">test_set</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_set_df</span> <span class="o">=</span> <span class="n">deep_net_models</span><span class="o">.</span><span class="n">train_multitask_regressor</span><span class="p">(</span>
            <span class="n">tasks</span><span class="o">=</span><span class="n">assay_targets</span><span class="p">,</span>
            <span class="n">data_df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">fit_transformers</span><span class="o">=</span><span class="n">fit_transformers</span><span class="p">,</span>
            <span class="n">smiles_column</span><span class="o">=</span><span class="n">smiles_column</span><span class="p">,</span>
            <span class="n">ids_column</span><span class="o">=</span><span class="n">name_column</span><span class="p">,</span>
            <span class="n">layer_sizes</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">],</span>
            <span class="n">activation_fns</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
            <span class="n">uncertainty</span><span class="o">=</span><span class="n">uncertainty</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">test_set_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;RMS&quot;</span><span class="p">,</span> <span class="s2">&quot;mean over tasks&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">error</span>

    <span class="k">elif</span> <span class="n">train_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">test_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">df</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_set_df</span> <span class="o">=</span> <span class="n">deep_net_models</span><span class="o">.</span><span class="n">train_multitask_regressor</span><span class="p">(</span>
            <span class="n">tasks</span><span class="o">=</span><span class="n">assay_targets</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span>
            <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span>
            <span class="n">valid_dataset</span><span class="o">=</span><span class="n">valid_set</span><span class="p">,</span>
            <span class="n">fit_transformers</span><span class="o">=</span><span class="n">fit_transformers</span><span class="p">,</span>
            <span class="n">layer_sizes</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">],</span>
            <span class="n">activation_fns</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
            <span class="n">uncertainty</span><span class="o">=</span><span class="n">uncertainty</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">test_set_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;RMS&quot;</span><span class="p">,</span> <span class="s2">&quot;mean over tasks&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">error</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;NO TRAINING IS HAPPENING&quot;</span><span class="p">)</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run_train_test_study_with_mlflow</span><span class="p">(</span>
    <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">],</span>
    <span class="bp">cls</span><span class="p">:</span> <span class="n">build_train_test_objective</span><span class="p">,</span>
    <span class="n">priors_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">holdout_set</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">JoinKfoldData</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NumpyDataset</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DiskDataset</span>
    <span class="p">],</span>
    <span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">directions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">mlflow_experiment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pipeline_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">local_abs_store_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_key_in_pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">BaseSampler</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">TPESampler</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">training_smiles</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to run a kfold study with mlflow logging the results and models for each trial</span>
<span class="sd">    Args:</span>
<span class="sd">        models (List[classical_ml_models.skmodel]): The models to run the kfold study on</span>
<span class="sd">        cls (build_train_test_objective): The class object to run the train test study</span>
<span class="sd">        pipe_or_model (Union[Pipeline, Callable]): The pipeline or model to optimize</span>
<span class="sd">        priors_dict (Optional[dict]): The priors to optimize over</span>
<span class="sd">        holdout_set (Union[JoinKfoldData, deepchem.data.NumpyDataset, deepchem.data.DiskDataset]): The holdout set to validate the models</span>
<span class="sd">        num_trials (int): The number of trials to run</span>
<span class="sd">        experiment_id (int): The mlflow experiment id</span>
<span class="sd">        directions (List[str]): The directions to optimize the objectives in</span>
<span class="sd">        mlflow_experiment_name (str): The mlflow experiment name</span>
<span class="sd">        local_abs_store_path (Optional[str], optional): The local absolute path to store the models. Defaults to None.</span>
<span class="sd">        model_key_in_pipeline (Optional[str], optional): The key to prepend to the model parameters in the pipeline. Defaults to &quot;model__&quot;.</span>
<span class="sd">        sampler (optuna.samplers.BaseSampler, optional): The sampler to use for the optimization. Defaults to optuna.samplers.TPESampler(seed=utilities.random_seed).</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[list[Any], int]: The studies and the experiment id</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">store_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_abs_store_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">experiment_id</span> <span class="o">=</span> <span class="n">ml_flow_funcs</span><span class="o">.</span><span class="n">setup_for_mlflow</span><span class="p">(</span>
        <span class="n">mlflow_experiment_name</span><span class="p">,</span> <span class="n">utilities</span><span class="o">.</span><span class="n">mlflow_local_uri</span>
    <span class="p">)</span>

    <span class="c1"># if training_smiles is given automatically create an applicability domain based on Tanimoto distance/similarity model and log it to mlflow.</span>
    <span class="c1"># It is the same for all prediction models.</span>
    <span class="k">if</span> <span class="n">training_smiles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Applicability_domain&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training smiles: </span><span class="si">{</span><span class="n">training_smiles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">admodel</span> <span class="o">=</span> <span class="n">applicability_domain</span><span class="o">.</span><span class="n">get_tanimoto_ad_model</span><span class="p">(</span>
                <span class="n">training_smiles</span><span class="o">=</span><span class="n">training_smiles</span><span class="p">,</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;brute&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">wadmodel</span> <span class="o">=</span> <span class="n">WrappedKNeighbors</span><span class="p">(</span><span class="n">admodel</span><span class="p">)</span>
            <span class="n">example_input</span> <span class="o">=</span> <span class="n">ml_featurization</span><span class="o">.</span><span class="n">get_ecfp</span><span class="p">(</span>
                <span class="n">smiles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;c1ccccc1&quot;</span><span class="p">,</span> <span class="s2">&quot;CCCCC&quot;</span><span class="p">,</span> <span class="s2">&quot;C(CCN)C(=O)O&quot;</span><span class="p">,</span> <span class="s2">&quot;c1ccccc1NC(=O)C&quot;</span><span class="p">],</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">return_np</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                <span class="n">sk_model</span><span class="o">=</span><span class="n">wadmodel</span><span class="p">,</span>
                <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;applicability_domain_model&quot;</span><span class="p">,</span>
                <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                    <span class="n">example_input</span><span class="p">,</span> <span class="n">wadmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;applicability_domain_kneighbours_tanimoto_distance_model&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_training_points&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_samples_fit_</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_features&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)</span>

    <span class="n">studies</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2"> is not an instance of skmodel&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">date_and_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2">-%m-%Y_%H-%M&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_store_path</span> <span class="o">=</span> <span class="n">store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="n">model_store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">priors_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">default_param_range_priors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">priors_dict</span>

        <span class="k">if</span> <span class="n">pipeline_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">pipeline_list</span> <span class="o">+</span> <span class="p">[(</span><span class="n">model_key_in_pipeline</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">pipe_or_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipe_or_model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">prepend_dictionary_keys</span><span class="p">(</span>
                <span class="n">priors</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key_in_pipeline</span><span class="si">}</span><span class="s2">__&quot;</span>
            <span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Priors: </span><span class="si">{</span><span class="n">priors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;train_test_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;sqlite:///</span><span class="si">{</span><span class="n">model_store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">date_and_time</span><span class="si">}</span><span class="s1">.db&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;For model </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> we will run </span><span class="si">{</span><span class="n">num_trials</span><span class="si">}</span><span class="s2"> trials to optimize the hyperparameters&quot;</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_training_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">trial</span><span class="p">:</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectivefx</span><span class="p">(</span>
                    <span class="n">trial</span><span class="p">,</span>
                    <span class="n">pipe_or_model</span><span class="p">,</span>
                    <span class="n">priors</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train_and_testing_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
                    <span class="n">experiment_description</span><span class="o">=</span><span class="n">experiment_description</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">n_trials</span><span class="o">=</span><span class="n">num_trials</span><span class="p">,</span>
                <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">gc_after_trial</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># Account for the absolute difference between the training and test set scores if its an objective</span>
            <span class="n">n_standard_ojectives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">n_standard_ojectives</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                    <span class="s2">&quot;abs_train_test_diff&quot;</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">n_standard_ojectives</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">ax_po</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span>
                    <span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ax_po</span><span class="p">))</span>
                <span class="n">ax_po</span><span class="o">.</span><span class="n">write_image</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>

            <span class="n">all_data_as_single_train_set_x</span><span class="p">,</span> <span class="n">all_data_as_single_train_set_y</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">get_all_data_as_single_set</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">validation_ojective_values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">validation_objective_indexes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bs</span> <span class="ow">in</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best trial: </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">mod</span> <span class="o">=</span> <span class="n">pipe_or_model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">bs</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">all_data_as_single_train_set_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">all_data_as_single_train_set_x</span><span class="p">,</span>
                    <span class="n">all_data_as_single_train_set_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                    <span class="n">sk_model</span><span class="o">=</span><span class="n">mod</span><span class="p">,</span>
                    <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                        <span class="n">all_data_as_single_train_set_x</span><span class="p">,</span>
                        <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">all_data_as_single_train_set_x</span><span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">input_example</span><span class="o">=</span><span class="n">all_data_as_single_train_set_x</span><span class="p">,</span>
                    <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train_test_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">validation_set_pred</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">validation_ojective_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">obj</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">validation_set_pred</span><span class="p">)</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">validation_objective_indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Validation set objective values for </span><span class="si">{</span><span class="n">validation_objective_indexes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">validation_ojective_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># plot the parity plot of the predictions</span>
                <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
                    <span class="nb">min</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
                    <span class="nb">max</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
                <span class="n">title_fontsize</span> <span class="o">=</span> <span class="mi">27</span>
                <span class="n">parity_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">xymin</span><span class="p">,</span>
                    <span class="n">xymax</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">parity_plt</span><span class="p">,</span>
                    <span class="s2">&quot;external_validation_set_parity_plot_train_test_validation.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">residual_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">residual_plt</span><span class="p">,</span>
                    <span class="s2">&quot;external_validation_set_residual_plot_train_test_validation.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">err_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">err_plt</span><span class="p">,</span>
                    <span class="s2">&quot;external_validation_set_error_plot_train_test_validation.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">qq_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">qq_plt</span><span class="p">,</span> <span class="s2">&quot;external_validation_set_qq_plot_train_test_validation.png&quot;</span>
                <span class="p">)</span>

            <span class="n">validation_metric_tab_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">validation_ojective_values</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="n">validation_objective_indexes</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index_label</span><span class="o">=</span><span class="s2">&quot;model&quot;</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_html</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">,</span> <span class="n">index_names</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">)</span>

            <span class="n">studies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">studies</span><span class="p">,</span> <span class="n">experiment_id</span>


<span class="k">def</span><span class="w"> </span><span class="nf">run_kfold_study_with_mlflow</span><span class="p">(</span>
    <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">],</span>
    <span class="bp">cls</span><span class="p">:</span> <span class="n">build_kfold_objective</span><span class="p">,</span>
    <span class="n">priors_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">pipeline_priors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">holdout_set</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">JoinKfoldData</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NumpyDataset</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DiskDataset</span>
    <span class="p">],</span>
    <span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">directions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">mlflow_experiment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pipeline_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">local_abs_store_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_key_in_pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">BaseSampler</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">TPESampler</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">training_smiles</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to run a kfold study with mlflow logging the results and models for each trial</span>
<span class="sd">    Args:</span>
<span class="sd">        models (List[classical_ml_models.skmodel]): The models to run the kfold study on</span>
<span class="sd">        cls (build_kfold_objective): The class object to run the kfold study</span>
<span class="sd">        pipe_or_model (Union[Pipeline, Callable]): The pipeline or model to optimize</span>
<span class="sd">        priors_dict (Optional[dict]): The priors to optimize over</span>
<span class="sd">        pipeline_priors (Optional[dict]): The priors to optimize over for the pipeline</span>
<span class="sd">        holdout_set (Union[JoinKfoldData, deepchem.data.NumpyDataset, deepchem.data.DiskDataset]): The holdout set to validate the models</span>
<span class="sd">        num_trials (int): The number of trials to run</span>
<span class="sd">        experiment_id (int): The mlflow experiment id</span>
<span class="sd">        directions (List[str]): The directions to optimize the objectives in</span>
<span class="sd">        mlflow_experiment_name (str): The mlflow experiment name</span>
<span class="sd">        local_abs_store_path (Optional[str], optional): The local absolute path to store the models. Defaults to None.</span>
<span class="sd">        model_key_in_pipeline (Optional[str], optional): The key to prepend to the model parameters in the pipeline. Defaults to &quot;model__&quot;.</span>
<span class="sd">        sampler (optuna.samplers.BaseSampler, optional): The sampler to use for the optimization. Defaults to optuna.samplers.TPESampler(seed=utilities.random_seed).</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[list[Any], int]: The studies and the experiment id</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">store_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_abs_store_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">experiment_id</span> <span class="o">=</span> <span class="n">ml_flow_funcs</span><span class="o">.</span><span class="n">setup_for_mlflow</span><span class="p">(</span>
        <span class="n">mlflow_experiment_name</span><span class="p">,</span> <span class="n">utilities</span><span class="o">.</span><span class="n">mlflow_local_uri</span>
    <span class="p">)</span>

    <span class="c1"># if training_smiles is given automatically create an applicability domain based on Tanimoto distance/similarity model and log it to mlflow.</span>
    <span class="c1"># It is the same for all prediction models.</span>
    <span class="k">if</span> <span class="n">training_smiles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Applicability_domain&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training smiles: </span><span class="si">{</span><span class="n">training_smiles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">admodel</span> <span class="o">=</span> <span class="n">applicability_domain</span><span class="o">.</span><span class="n">get_tanimoto_ad_model</span><span class="p">(</span>
                <span class="n">training_smiles</span><span class="o">=</span><span class="n">training_smiles</span><span class="p">,</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;brute&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">wadmodel</span> <span class="o">=</span> <span class="n">WrappedKNeighbors</span><span class="p">(</span><span class="n">admodel</span><span class="p">)</span>
            <span class="n">example_input</span> <span class="o">=</span> <span class="n">ml_featurization</span><span class="o">.</span><span class="n">get_ecfp</span><span class="p">(</span>
                <span class="n">smiles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;c1ccccc1&quot;</span><span class="p">,</span> <span class="s2">&quot;CCCCC&quot;</span><span class="p">,</span> <span class="s2">&quot;C(CCN)C(=O)O&quot;</span><span class="p">,</span> <span class="s2">&quot;c1ccccc1NC(=O)C&quot;</span><span class="p">],</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">return_np</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                <span class="n">sk_model</span><span class="o">=</span><span class="n">wadmodel</span><span class="p">,</span>
                <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;applicability_domain_model&quot;</span><span class="p">,</span>
                <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                    <span class="n">example_input</span><span class="p">,</span> <span class="n">wadmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;applicability_domain_kneighbours_tanimoto_distance_model&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_training_points&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_samples_fit_</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_features&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)</span>

    <span class="n">studies</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2"> is not an instance of skmodel&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">date_and_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2">-%m-%Y_%H-%M&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_store_path</span> <span class="o">=</span> <span class="n">store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="n">model_store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">priors_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">default_param_range_priors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">priors_dict</span>

        <span class="k">if</span> <span class="n">pipeline_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">pipeline_list</span> <span class="o">+</span> <span class="p">[(</span><span class="n">model_key_in_pipeline</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">pipe_or_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipe_or_model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">prepend_dictionary_keys</span><span class="p">(</span>
                <span class="n">priors</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key_in_pipeline</span><span class="si">}</span><span class="s2">__&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">pipeline_priors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">priors</span><span class="p">,</span> <span class="o">**</span><span class="n">pipeline_priors</span><span class="p">}</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Priors: </span><span class="si">{</span><span class="n">priors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">k</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;sqlite:///</span><span class="si">{</span><span class="n">model_store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">date_and_time</span><span class="si">}</span><span class="s1">.db&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;For model </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> we will run </span><span class="si">{</span><span class="n">num_trials</span><span class="si">}</span><span class="s2"> trials to optimize the hyperparameters&quot;</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_training_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">trial</span><span class="p">:</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectivefx</span><span class="p">(</span>
                    <span class="n">trial</span><span class="p">,</span>
                    <span class="n">pipe_or_model</span><span class="p">,</span>
                    <span class="n">priors</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
                    <span class="n">experiment_description</span><span class="o">=</span><span class="n">experiment_description</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">n_trials</span><span class="o">=</span><span class="n">num_trials</span><span class="p">,</span>
                <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">gc_after_trial</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># Account for the absolute difference between the training and test set scores if its an objective</span>
            <span class="n">n_standard_ojectives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">n_standard_ojectives</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                    <span class="s2">&quot;abs_train_test_diff&quot;</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">n_standard_ojectives</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">ax_po</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span>
                    <span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ax_po</span><span class="p">))</span>
                <span class="n">ax_po</span><span class="o">.</span><span class="n">write_image</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>

            <span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span> <span class="n">all_data_as_single_train_fold_y</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">get_all_data_as_single_fold</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">validation_ojective_values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">validation_objective_indexes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bs</span> <span class="ow">in</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best trial: </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">mod</span> <span class="o">=</span> <span class="n">pipe_or_model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">bs</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">all_data_as_single_train_fold_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span>
                    <span class="n">all_data_as_single_train_fold_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                    <span class="n">sk_model</span><span class="o">=</span><span class="n">mod</span><span class="p">,</span>
                    <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                        <span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span>
                        <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">all_data_as_single_train_fold_X</span><span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">input_example</span><span class="o">=</span><span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span>
                    <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">validation_set_pred</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">validation_ojective_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">obj</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">validation_set_pred</span><span class="p">)</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">validation_objective_indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Validation set objective values for </span><span class="si">{</span><span class="n">validation_objective_indexes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">validation_ojective_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># plot the parity plot of the predictions</span>
                <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
                    <span class="nb">min</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
                    <span class="nb">max</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
                <span class="n">title_fontsize</span> <span class="o">=</span> <span class="mi">27</span>
                <span class="n">parity_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">xymin</span><span class="p">,</span>
                    <span class="n">xymax</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">parity_plt</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;external_validation_set_parity_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">residual_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">residual_plt</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;external_validation_set_residual_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">err_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">err_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;external_validation_set_error_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>
                <span class="n">qq_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">qq_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;external_validation_set_qq_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>

            <span class="n">validation_metric_tab_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">validation_ojective_values</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="n">validation_objective_indexes</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index_label</span><span class="o">=</span><span class="s2">&quot;model&quot;</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_html</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">,</span> <span class="n">index_names</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">)</span>

            <span class="n">studies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">studies</span><span class="p">,</span> <span class="n">experiment_id</span>


<span class="k">def</span><span class="w"> </span><span class="nf">build_param_grid</span><span class="p">(</span>
    <span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build the parameter grid for the optimization</span>
<span class="sd">    Args:</span>
<span class="sd">        parameters (dict): The parameters to optimize over</span>
<span class="sd">        trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">        param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict[Any, Any]: The parameter grid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;catagorical&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">param_grid</span>


<span class="k">def</span><span class="w"> </span><span class="nf">objective_defined_train_test_single_rmse</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressor</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to train a model on the train set and evaluate the metrics on a test set.</span>
<span class="sd">    This means the test set is used to optimize the hyper-parameters, therefore you MUST</span>
<span class="sd">    have a separate validation set tp test the model on.</span>

<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial._trial.Trial): An Optuna trial set for hyper-parameters</span>
<span class="sd">        regressor (Callable): A regressor function or sklearn pipeline to set the parameter to from the trial</span>
<span class="sd">        parameters (dict): A dictionary of parameter ranges</span>
<span class="sd">        X_train (Union[pd.DataFrame, np.ndarray]): the training set and features</span>
<span class="sd">        X_test (Union[pd.DataFrame, np.ndarray]): the test set and features</span>
<span class="sd">        y_train (Union[pd.Series, np.ndarray]): the training set known target values for a property of interest</span>
<span class="sd">        y_test(Union[pd.Series, np.ndarray]): the test set  known target values for a property of interest</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[np.float64, float]: RMSE</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">tmp_r</span> <span class="o">=</span> <span class="n">regressor</span><span class="p">()</span>
        <span class="n">tmp_r</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;random_state&quot;</span><span class="p">)</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">}</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Regressor does not use a random_state for reproducibility on initialization&quot;</span>
        <span class="p">)</span>

    <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressor</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">error</span>


<span class="k">def</span><span class="w"> </span><span class="nf">layer_size_to_network</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">n_layer_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;n_layers&quot;</span><span class="p">,</span>
    <span class="n">min_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">max_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">prepend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    _summary_</span>

<span class="sd">    Args:</span>
<span class="sd">        param_grid (dict): _description_</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">ith</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">param_grid</span><span class="p">[</span><span class="n">n_layer_key</span><span class="p">]):</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_n_nodes&quot;</span><span class="p">,</span> <span class="n">min_nodes</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">))</span>

    <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;layers: </span><span class="si">{</span><span class="n">layers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">prepend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">param_grid</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prepend</span><span class="si">}</span><span class="s2">hidden_layer_sizes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">n_layer_key</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">param_grid</span>


<span class="k">def</span><span class="w"> </span><span class="nf">objective_random_cv_multi_rmse__r2__diff_train_test</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">randomize_cv_split</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">k_fold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to do an internal random cv over X and y</span>

<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial.Trial): _description_</span>
<span class="sd">        regressorfx (Callable): _description_</span>
<span class="sd">        parameters (_type_): _description_</span>
<span class="sd">        X (Union[pd.DataFrame, np.ndarray]): _description_</span>
<span class="sd">        y (Union[pd.Series, np.ndarray]): _description_</span>
<span class="sd">        randomize_cv_split (bool, optional): _description_. Defaults to False.</span>
<span class="sd">        update_param_grid_callback (Optional[Callable], optional): _description_. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[ Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float ]: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>

    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">randomize_cv_split</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">*</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">second</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k_fold</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">cv_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k_fold</span><span class="p">)</span>
    <span class="n">cv_r2_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k_fold</span><span class="p">)</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k_fold</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
        <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">train_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">cv_r2_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">cv_rmse_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

    <span class="n">mean_cv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">)</span>
    <span class="n">r2_coefficent_of_determination</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_r2_scores</span><span class="p">)</span>
    <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">mean_cv</span><span class="p">,</span> <span class="n">r2_coefficent_of_determination</span><span class="p">,</span> <span class="n">train_val_abs_diff</span>


<span class="k">def</span><span class="w"> </span><span class="nf">objective_predefined_cv_multi_rmse__r2__diff_train_test</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">predfined_kfolds</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mlflow_address</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to do an internal random cv over X and y</span>

<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial.Trial): _description_</span>
<span class="sd">        regressorfx (Callable): _description_</span>
<span class="sd">        parameters (_type_): _description_</span>
<span class="sd">        predfined_kfolds (Tuple[np.ndarray]): _description_</span>
<span class="sd">        update_param_grid_callback (Optional[Callable], optional): _description_. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[ Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float ]: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>

    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">cv_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">))</span>
    <span class="n">cv_r2_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">))</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Get training set predcition scores to minimize the difference between this and the test set score</span>
        <span class="n">train_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="c1"># regression metric scores coefficent of determination and RMSE</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">cv_r2_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">cv_rmse_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cv_r2_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">cv_rmse_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">))</span>

    <span class="n">mean_cv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">)</span>
    <span class="n">r2_coefficent_of_determination</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_r2_scores</span><span class="p">)</span>
    <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">mean_cv</span><span class="p">,</span> <span class="n">r2_coefficent_of_determination</span><span class="p">,</span> <span class="n">train_val_abs_diff</span>
</pre></div>

  </div>

  </header>

  <section id="section-items">
    <h2 class="section-title" id="header-variables">Module variables</h2>
      <div class="item">
      <p id="redxregressors.tune.log" class="name">var <span class="ident">log</span></p>


  <div class="source_cont">
</div>

      </div>

    <h2 class="section-title" id="header-functions">Functions</h2>

  <div class="item">
    <div class="name def" id="redxregressors.tune.build_param_grid">
    <p>def <span class="ident">build_param_grid</span>(</p><p>parameters, trial: optuna.trial._trial.Trial, param_grid: Optional[dict] = None)</p>
    </div>




    <div class="desc"><p>Function to build the parameter grid for the optimization
Args:
    parameters (dict): The parameters to optimize over
    trial (optuna.trial.Trial): The optuna trial object
    param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.
Returns:
    dict[Any, Any]: The parameter grid</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_param_grid', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_param_grid" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">build_param_grid</span><span class="p">(</span>
    <span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build the parameter grid for the optimization</span>
<span class="sd">    Args:</span>
<span class="sd">        parameters (dict): The parameters to optimize over</span>
<span class="sd">        trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">        param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict[Any, Any]: The parameter grid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;catagorical&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">param_grid</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.layer_size_to_network">
    <p>def <span class="ident">layer_size_to_network</span>(</p><p>trial: optuna.trial._trial.Trial, param_grid: dict, n_layer_key: str = &#39;n_layers&#39;, min_nodes: int = 10, max_nodes: int = 100, prepend: Optional[str] = None)</p>
    </div>




    <div class="desc"><p><em>summary</em></p>
<p>Args:
    param_grid (dict): <em>description</em></p>
<p>Returns:
    dict: <em>description</em></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.layer_size_to_network', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.layer_size_to_network" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">layer_size_to_network</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">param_grid</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">n_layer_key</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;n_layers&quot;</span><span class="p">,</span>
    <span class="n">min_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">max_nodes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">prepend</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    _summary_</span>

<span class="sd">    Args:</span>
<span class="sd">        param_grid (dict): _description_</span>

<span class="sd">    Returns:</span>
<span class="sd">        dict: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">layers</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">ith</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">param_grid</span><span class="p">[</span><span class="n">n_layer_key</span><span class="p">]):</span>
        <span class="n">layers</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_n_nodes&quot;</span><span class="p">,</span> <span class="n">min_nodes</span><span class="p">,</span> <span class="n">max_nodes</span><span class="p">))</span>

    <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;layers: </span><span class="si">{</span><span class="n">layers</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">prepend</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">param_grid</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">prepend</span><span class="si">}</span><span class="s2">hidden_layer_sizes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span>

    <span class="n">_</span> <span class="o">=</span> <span class="n">param_grid</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="n">n_layer_key</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">param_grid</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.objective_defined_train_test_single_rmse">
    <p>def <span class="ident">objective_defined_train_test_single_rmse</span>(</p><p>trial: optuna.trial._trial.Trial, regressor: Callable, parameters: dict, X_train: Union[pandas.core.frame.DataFrame, numpy.ndarray], X_test: Union[pandas.core.frame.DataFrame, numpy.ndarray], y_train: Union[pandas.core.series.Series, numpy.ndarray], y_test: Union[pandas.core.series.Series, numpy.ndarray])</p>
    </div>




    <div class="desc"><p>Function to train a model on the train set and evaluate the metrics on a test set.
This means the test set is used to optimize the hyper-parameters, therefore you MUST
have a separate validation set tp test the model on.</p>
<p>Args:
    trial (optuna.trial._trial.Trial): An Optuna trial set for hyper-parameters
    regressor (Callable): A regressor function or sklearn pipeline to set the parameter to from the trial
    parameters (dict): A dictionary of parameter ranges
    X_train (Union[pd.DataFrame, np.ndarray]): the training set and features
    X_test (Union[pd.DataFrame, np.ndarray]): the test set and features
    y_train (Union[pd.Series, np.ndarray]): the training set known target values for a property of interest
    y_test(Union[pd.Series, np.ndarray]): the test set  known target values for a property of interest</p>
<p>Returns:
    Union[np.float64, float]: RMSE</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.objective_defined_train_test_single_rmse', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.objective_defined_train_test_single_rmse" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objective_defined_train_test_single_rmse</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressor</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">X_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_train</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y_test</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to train a model on the train set and evaluate the metrics on a test set.</span>
<span class="sd">    This means the test set is used to optimize the hyper-parameters, therefore you MUST</span>
<span class="sd">    have a separate validation set tp test the model on.</span>

<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial._trial.Trial): An Optuna trial set for hyper-parameters</span>
<span class="sd">        regressor (Callable): A regressor function or sklearn pipeline to set the parameter to from the trial</span>
<span class="sd">        parameters (dict): A dictionary of parameter ranges</span>
<span class="sd">        X_train (Union[pd.DataFrame, np.ndarray]): the training set and features</span>
<span class="sd">        X_test (Union[pd.DataFrame, np.ndarray]): the test set and features</span>
<span class="sd">        y_train (Union[pd.Series, np.ndarray]): the training set known target values for a property of interest</span>
<span class="sd">        y_test(Union[pd.Series, np.ndarray]): the test set  known target values for a property of interest</span>

<span class="sd">    Returns:</span>
<span class="sd">        Union[np.float64, float]: RMSE</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">tmp_r</span> <span class="o">=</span> <span class="n">regressor</span><span class="p">()</span>
        <span class="n">tmp_r</span><span class="o">.</span><span class="fm">__getattribute__</span><span class="p">(</span><span class="s2">&quot;random_state&quot;</span><span class="p">)</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;random_state&quot;</span><span class="p">:</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">}</span>
    <span class="k">except</span> <span class="ne">AttributeError</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="s2">&quot;Regressor does not use a random_state for reproducibility on initialization&quot;</span>
        <span class="p">)</span>

    <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressor</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

    <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

    <span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">error</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.objective_predefined_cv_multi_rmse__r2__diff_train_test">
    <p>def <span class="ident">objective_predefined_cv_multi_rmse__r2__diff_train_test</span>(</p><p>trial: optuna.trial._trial.Trial, regressorfx: Any, parameters: dict, predfined_kfolds: Tuple[numpy.ndarray], update_param_grid_callback: Optional[Callable] = None, mlflow_address: Optional[str] = None, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to do an internal random cv over X and y</p>
<p>Args:
    trial (optuna.trial.Trial): <em>description</em>
    regressorfx (Callable): <em>description</em>
    parameters (<em>type</em>): <em>description</em>
    predfined_kfolds (Tuple[np.ndarray]): <em>description</em>
    update_param_grid_callback (Optional[Callable], optional): <em>description</em>. Defaults to None.</p>
<p>Returns:
    Tuple[ Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float ]: <em>description</em></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.objective_predefined_cv_multi_rmse__r2__diff_train_test', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.objective_predefined_cv_multi_rmse__r2__diff_train_test" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objective_predefined_cv_multi_rmse__r2__diff_train_test</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">predfined_kfolds</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">mlflow_address</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to do an internal random cv over X and y</span>

<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial.Trial): _description_</span>
<span class="sd">        regressorfx (Callable): _description_</span>
<span class="sd">        parameters (_type_): _description_</span>
<span class="sd">        predfined_kfolds (Tuple[np.ndarray]): _description_</span>
<span class="sd">        update_param_grid_callback (Optional[Callable], optional): _description_. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[ Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float ]: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>

    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="n">cv_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">))</span>
    <span class="n">cv_r2_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">))</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">train</span><span class="p">,</span> <span class="n">test</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">predfined_kfolds</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">())</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>

        <span class="c1"># Get training set predcition scores to minimize the difference between this and the test set score</span>
        <span class="n">train_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">train</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
        <span class="p">)</span>

        <span class="c1"># regression metric scores coefficent of determination and RMSE</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">cv_r2_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">cv_rmse_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">cv_r2_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">)</span>
            <span class="n">cv_rmse_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span> <span class="n">y_pred</span><span class="p">))</span>

    <span class="n">mean_cv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">)</span>
    <span class="n">r2_coefficent_of_determination</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_r2_scores</span><span class="p">)</span>
    <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">mean_cv</span><span class="p">,</span> <span class="n">r2_coefficent_of_determination</span><span class="p">,</span> <span class="n">train_val_abs_diff</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.objective_random_cv_multi_rmse__r2__diff_train_test">
    <p>def <span class="ident">objective_random_cv_multi_rmse__r2__diff_train_test</span>(</p><p>trial: optuna.trial._trial.Trial, regressorfx: Callable, parameters, X: Union[pandas.core.frame.DataFrame, numpy.ndarray], y: Union[pandas.core.series.Series, numpy.ndarray], randomize_cv_split: bool = False, update_param_grid_callback: Optional[Callable] = None, k_fold: int = 5, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to do an internal random cv over X and y</p>
<p>Args:
    trial (optuna.trial.Trial): <em>description</em>
    regressorfx (Callable): <em>description</em>
    parameters (<em>type</em>): <em>description</em>
    X (Union[pd.DataFrame, np.ndarray]): <em>description</em>
    y (Union[pd.Series, np.ndarray]): <em>description</em>
    randomize_cv_split (bool, optional): <em>description</em>. Defaults to False.
    update_param_grid_callback (Optional[Callable], optional): <em>description</em>. Defaults to None.</p>
<p>Returns:
    Tuple[ Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float ]: <em>description</em></p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.objective_random_cv_multi_rmse__r2__diff_train_test', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.objective_random_cv_multi_rmse__r2__diff_train_test" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objective_random_cv_multi_rmse__r2__diff_train_test</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">],</span>
    <span class="n">randomize_cv_split</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">k_fold</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">5</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to do an internal random cv over X and y</span>

<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial.Trial): _description_</span>
<span class="sd">        regressorfx (Callable): _description_</span>
<span class="sd">        parameters (_type_): _description_</span>
<span class="sd">        X (Union[pd.DataFrame, np.ndarray]): _description_</span>
<span class="sd">        y (Union[pd.Series, np.ndarray]): _description_</span>
<span class="sd">        randomize_cv_split (bool, optional): _description_. Defaults to False.</span>
<span class="sd">        update_param_grid_callback (Optional[Callable], optional): _description_. Defaults to None.</span>

<span class="sd">    Returns:</span>
<span class="sd">        Tuple[ Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float ]: _description_</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="n">build_param_grid</span><span class="p">(</span><span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">)</span>

    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="n">param_grid</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">update_param_grid_callback</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="n">update_param_grid_callback</span><span class="p">(</span><span class="n">trial</span><span class="p">,</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">param_grid</span><span class="p">),</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">):</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">randomize_cv_split</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span> <span class="o">*</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">second</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">seed</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span>

    <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="n">k_fold</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">cv_rmse_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k_fold</span><span class="p">)</span>
    <span class="n">cv_r2_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k_fold</span><span class="p">)</span>
    <span class="n">train_scores</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">(</span><span class="n">k_fold</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">train_idx</span><span class="p">,</span> <span class="n">test_idx</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)):</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">regressorfx</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;random_state&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span>
            <span class="n">regressor</span> <span class="o">=</span> <span class="n">regressorfx</span><span class="p">(</span><span class="o">**</span><span class="n">param_grid</span><span class="p">)</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>

        <span class="n">y_train</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">train_idx</span><span class="p">]</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="n">test_idx</span><span class="p">]</span>
        <span class="n">regressor</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">train_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train</span><span class="p">))</span>
        <span class="p">)</span>
        <span class="n">cv_r2_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">cv_rmse_scores</span><span class="p">[</span><span class="n">ith</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">))</span>

    <span class="n">mean_cv</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">)</span>
    <span class="n">r2_coefficent_of_determination</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_r2_scores</span><span class="p">)</span>
    <span class="n">train_val_abs_diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">cv_rmse_scores</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">mean_cv</span><span class="p">,</span> <span class="n">r2_coefficent_of_determination</span><span class="p">,</span> <span class="n">train_val_abs_diff</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.optimize_dnn_arch_and_train">
    <p>def <span class="ident">optimize_dnn_arch_and_train</span>(</p><p>trial: optuna.trial._trial.Trial, assay_targets: List[str], decreasing_neurons_only: bool = False, uncertainty: bool = True, epochs: int = 100, fit_transformers: Optional[List[transformers.Transformer]] = None, train_set: Optional[deepchem.data.data_loader.DataLoader] = None, valid_set: Optional[deepchem.data.data_loader.DataLoader] = None, test_set: Optional[deepchem.data.data_loader.DataLoader] = None, df: Optional[pandas.core.frame.DataFrame] = None, smiles_column: Optional[str] = None, name_column: Optional[str] = None, parameters: Optional[dict] = None, verbose: bool = False)</p>
    </div>




  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.optimize_dnn_arch_and_train', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.optimize_dnn_arch_and_train" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">optimize_dnn_arch_and_train</span><span class="p">(</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">assay_targets</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">decreasing_neurons_only</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="n">uncertainty</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">epochs</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">fit_transformers</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">trans</span><span class="o">.</span><span class="n">Transformer</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_set</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_loader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">valid_set</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_loader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">test_set</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">dc</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">data_loader</span><span class="o">.</span><span class="n">DataLoader</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">df</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">smiles_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name_column</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">parameters</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
            <span class="s2">&quot;n_neurons&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
            <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span>
        <span class="p">}</span>

    <span class="c1"># Ensures all the expected keys are present in the parameters dictionary</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">default_parameters</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>
            <span class="s2">&quot;n_neurons&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">1000</span><span class="p">),</span>
            <span class="s2">&quot;dropout_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
            <span class="s2">&quot;activation&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;categorical&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s2">&quot;relu&quot;</span><span class="p">,</span> <span class="s2">&quot;sigmoid&quot;</span><span class="p">,</span> <span class="s2">&quot;tanh&quot;</span><span class="p">]),</span>
            <span class="s2">&quot;learning_rate&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;float&quot;</span><span class="p">,</span> <span class="mf">1e-6</span><span class="p">,</span> <span class="mf">1e-2</span><span class="p">),</span>
            <span class="s2">&quot;batch_size&quot;</span><span class="p">:</span> <span class="p">(</span><span class="s2">&quot;int&quot;</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">128</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">parameters</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">default_parameters</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">}</span>

    <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span>
        <span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">,</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
        <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
    <span class="p">)</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
        <span class="s2">&quot;learning_rate&quot;</span><span class="p">,</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span>
        <span class="s2">&quot;batch_size&quot;</span><span class="p">,</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="n">layer_sizes</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">activation_funcs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">drop_out</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">ith</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;n_hidden_layers&quot;</span><span class="p">]):</span>
        <span class="k">if</span> <span class="n">decreasing_neurons_only</span> <span class="ow">is</span> <span class="kc">True</span> <span class="ow">and</span> <span class="n">ith</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">layer_sizes</span> <span class="o">/</span> <span class="mi">10</span><span class="p">),</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">layer_sizes</span> <span class="o">/</span> <span class="mi">2</span><span class="p">),</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">lower</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">upper</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;n_neurons&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">]</span>

        <span class="n">layer_sizes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n_neurons_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">lower</span><span class="p">,</span> <span class="n">upper</span><span class="p">))</span>
        <span class="n">activation_funcs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;activation_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">])</span>
        <span class="p">)</span>
        <span class="n">drop_out</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
            <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;dropout_rate_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                <span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">][</span><span class="mi">2</span><span class="p">],</span>
            <span class="p">)</span>
        <span class="p">)</span>

    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer_sizes</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">activation_funcs</span>
    <span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">drop_out</span>

    <span class="k">if</span> <span class="n">verbose</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Parameter grid: </span><span class="si">{</span><span class="n">param_grid</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">train_set</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">test_set</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">df</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_set_df</span> <span class="o">=</span> <span class="n">deep_net_models</span><span class="o">.</span><span class="n">train_multitask_regressor</span><span class="p">(</span>
            <span class="n">tasks</span><span class="o">=</span><span class="n">assay_targets</span><span class="p">,</span>
            <span class="n">data_df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span>
            <span class="n">fit_transformers</span><span class="o">=</span><span class="n">fit_transformers</span><span class="p">,</span>
            <span class="n">smiles_column</span><span class="o">=</span><span class="n">smiles_column</span><span class="p">,</span>
            <span class="n">ids_column</span><span class="o">=</span><span class="n">name_column</span><span class="p">,</span>
            <span class="n">layer_sizes</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">],</span>
            <span class="n">activation_fns</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
            <span class="n">uncertainty</span><span class="o">=</span><span class="n">uncertainty</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">test_set_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;RMS&quot;</span><span class="p">,</span> <span class="s2">&quot;mean over tasks&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">error</span>

    <span class="k">elif</span> <span class="n">train_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">test_set</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">df</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">test_set_df</span> <span class="o">=</span> <span class="n">deep_net_models</span><span class="o">.</span><span class="n">train_multitask_regressor</span><span class="p">(</span>
            <span class="n">tasks</span><span class="o">=</span><span class="n">assay_targets</span><span class="p">,</span>
            <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_set</span><span class="p">,</span>
            <span class="n">test_dataset</span><span class="o">=</span><span class="n">test_set</span><span class="p">,</span>
            <span class="n">valid_dataset</span><span class="o">=</span><span class="n">valid_set</span><span class="p">,</span>
            <span class="n">fit_transformers</span><span class="o">=</span><span class="n">fit_transformers</span><span class="p">,</span>
            <span class="n">layer_sizes</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;hidden_layer_sizes&quot;</span><span class="p">],</span>
            <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;batch_size&quot;</span><span class="p">],</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;learning_rate&quot;</span><span class="p">],</span>
            <span class="n">dropout_rate</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;dropout_rate&quot;</span><span class="p">],</span>
            <span class="n">activation_fns</span><span class="o">=</span><span class="n">param_grid</span><span class="p">[</span><span class="s2">&quot;activation&quot;</span><span class="p">],</span>
            <span class="n">uncertainty</span><span class="o">=</span><span class="n">uncertainty</span><span class="p">,</span>
        <span class="p">)</span>

        <span class="n">error</span> <span class="o">=</span> <span class="n">test_set_df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="s2">&quot;RMS&quot;</span><span class="p">,</span> <span class="s2">&quot;mean over tasks&quot;</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">error</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;NO TRAINING IS HAPPENING&quot;</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.run_kfold_study_with_mlflow">
    <p>def <span class="ident">run_kfold_study_with_mlflow</span>(</p><p>models: List[redxregressors.classical_ml_models.skmodel], cls: tune.build_kfold_objective, priors_dict: Optional[dict], pipeline_priors: Optional[dict], holdout_set: Union[tune.JoinKfoldData, deepchem.data.datasets.NumpyDataset, deepchem.data.datasets.DiskDataset], num_trials: int, directions: List[str], mlflow_experiment_name: str, experiment_id: Optional[int] = None, pipeline_list: Optional[List[Tuple[str, Callable]]] = None, local_abs_store_path: Optional[str] = None, model_key_in_pipeline: Optional[str] = &#39;model&#39;, sampler: optuna.samplers._base.BaseSampler = &lt;optuna.samplers._tpe.sampler.TPESampler object at 0x342f32850&gt;, training_smiles: Optional[List[str]] = None, experiment_description: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to run a kfold study with mlflow logging the results and models for each trial
Args:
    models (List[classical_ml_models.skmodel]): The models to run the kfold study on
    cls (build_kfold_objective): The class object to run the kfold study
    pipe_or_model (Union[Pipeline, Callable]): The pipeline or model to optimize
    priors_dict (Optional[dict]): The priors to optimize over
    pipeline_priors (Optional[dict]): The priors to optimize over for the pipeline
    holdout_set (Union[JoinKfoldData, deepchem.data.NumpyDataset, deepchem.data.DiskDataset]): The holdout set to validate the models
    num_trials (int): The number of trials to run
    experiment_id (int): The mlflow experiment id
    directions (List[str]): The directions to optimize the objectives in
    mlflow_experiment_name (str): The mlflow experiment name
    local_abs_store_path (Optional[str], optional): The local absolute path to store the models. Defaults to None.
    model_key_in_pipeline (Optional[str], optional): The key to prepend to the model parameters in the pipeline. Defaults to "model__".
    sampler (optuna.samplers.BaseSampler, optional): The sampler to use for the optimization. Defaults to optuna.samplers.TPESampler(seed=utilities.random_seed).</p>
<p>Returns:
    tuple[list[Any], int]: The studies and the experiment id</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.run_kfold_study_with_mlflow', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.run_kfold_study_with_mlflow" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_kfold_study_with_mlflow</span><span class="p">(</span>
    <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">],</span>
    <span class="bp">cls</span><span class="p">:</span> <span class="n">build_kfold_objective</span><span class="p">,</span>
    <span class="n">priors_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">pipeline_priors</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">holdout_set</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">JoinKfoldData</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NumpyDataset</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DiskDataset</span>
    <span class="p">],</span>
    <span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">directions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">mlflow_experiment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pipeline_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">local_abs_store_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_key_in_pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">BaseSampler</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">TPESampler</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">training_smiles</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to run a kfold study with mlflow logging the results and models for each trial</span>
<span class="sd">    Args:</span>
<span class="sd">        models (List[classical_ml_models.skmodel]): The models to run the kfold study on</span>
<span class="sd">        cls (build_kfold_objective): The class object to run the kfold study</span>
<span class="sd">        pipe_or_model (Union[Pipeline, Callable]): The pipeline or model to optimize</span>
<span class="sd">        priors_dict (Optional[dict]): The priors to optimize over</span>
<span class="sd">        pipeline_priors (Optional[dict]): The priors to optimize over for the pipeline</span>
<span class="sd">        holdout_set (Union[JoinKfoldData, deepchem.data.NumpyDataset, deepchem.data.DiskDataset]): The holdout set to validate the models</span>
<span class="sd">        num_trials (int): The number of trials to run</span>
<span class="sd">        experiment_id (int): The mlflow experiment id</span>
<span class="sd">        directions (List[str]): The directions to optimize the objectives in</span>
<span class="sd">        mlflow_experiment_name (str): The mlflow experiment name</span>
<span class="sd">        local_abs_store_path (Optional[str], optional): The local absolute path to store the models. Defaults to None.</span>
<span class="sd">        model_key_in_pipeline (Optional[str], optional): The key to prepend to the model parameters in the pipeline. Defaults to &quot;model__&quot;.</span>
<span class="sd">        sampler (optuna.samplers.BaseSampler, optional): The sampler to use for the optimization. Defaults to optuna.samplers.TPESampler(seed=utilities.random_seed).</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[list[Any], int]: The studies and the experiment id</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">store_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_abs_store_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">experiment_id</span> <span class="o">=</span> <span class="n">ml_flow_funcs</span><span class="o">.</span><span class="n">setup_for_mlflow</span><span class="p">(</span>
        <span class="n">mlflow_experiment_name</span><span class="p">,</span> <span class="n">utilities</span><span class="o">.</span><span class="n">mlflow_local_uri</span>
    <span class="p">)</span>

    <span class="c1"># if training_smiles is given automatically create an applicability domain based on Tanimoto distance/similarity model and log it to mlflow.</span>
    <span class="c1"># It is the same for all prediction models.</span>
    <span class="k">if</span> <span class="n">training_smiles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Applicability_domain&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training smiles: </span><span class="si">{</span><span class="n">training_smiles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">admodel</span> <span class="o">=</span> <span class="n">applicability_domain</span><span class="o">.</span><span class="n">get_tanimoto_ad_model</span><span class="p">(</span>
                <span class="n">training_smiles</span><span class="o">=</span><span class="n">training_smiles</span><span class="p">,</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;brute&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">wadmodel</span> <span class="o">=</span> <span class="n">WrappedKNeighbors</span><span class="p">(</span><span class="n">admodel</span><span class="p">)</span>
            <span class="n">example_input</span> <span class="o">=</span> <span class="n">ml_featurization</span><span class="o">.</span><span class="n">get_ecfp</span><span class="p">(</span>
                <span class="n">smiles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;c1ccccc1&quot;</span><span class="p">,</span> <span class="s2">&quot;CCCCC&quot;</span><span class="p">,</span> <span class="s2">&quot;C(CCN)C(=O)O&quot;</span><span class="p">,</span> <span class="s2">&quot;c1ccccc1NC(=O)C&quot;</span><span class="p">],</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">return_np</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                <span class="n">sk_model</span><span class="o">=</span><span class="n">wadmodel</span><span class="p">,</span>
                <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;applicability_domain_model&quot;</span><span class="p">,</span>
                <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                    <span class="n">example_input</span><span class="p">,</span> <span class="n">wadmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;applicability_domain_kneighbours_tanimoto_distance_model&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_training_points&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_samples_fit_</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_features&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)</span>

    <span class="n">studies</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2"> is not an instance of skmodel&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">date_and_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2">-%m-%Y_%H-%M&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_store_path</span> <span class="o">=</span> <span class="n">store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="n">model_store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">priors_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">default_param_range_priors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">priors_dict</span>

        <span class="k">if</span> <span class="n">pipeline_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">pipeline_list</span> <span class="o">+</span> <span class="p">[(</span><span class="n">model_key_in_pipeline</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">pipe_or_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipe_or_model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">prepend_dictionary_keys</span><span class="p">(</span>
                <span class="n">priors</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key_in_pipeline</span><span class="si">}</span><span class="s2">__&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">pipeline_priors</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="p">{</span><span class="o">**</span><span class="n">priors</span><span class="p">,</span> <span class="o">**</span><span class="n">pipeline_priors</span><span class="p">}</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Priors: </span><span class="si">{</span><span class="n">priors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="bp">cls</span><span class="o">.</span><span class="n">k</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;sqlite:///</span><span class="si">{</span><span class="n">model_store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">date_and_time</span><span class="si">}</span><span class="s1">.db&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;For model </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> we will run </span><span class="si">{</span><span class="n">num_trials</span><span class="si">}</span><span class="s2"> trials to optimize the hyperparameters&quot;</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_training_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">trial</span><span class="p">:</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectivefx</span><span class="p">(</span>
                    <span class="n">trial</span><span class="p">,</span>
                    <span class="n">pipe_or_model</span><span class="p">,</span>
                    <span class="n">priors</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
                    <span class="n">experiment_description</span><span class="o">=</span><span class="n">experiment_description</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">n_trials</span><span class="o">=</span><span class="n">num_trials</span><span class="p">,</span>
                <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">gc_after_trial</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># Account for the absolute difference between the training and test set scores if its an objective</span>
            <span class="n">n_standard_ojectives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">n_standard_ojectives</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                    <span class="s2">&quot;abs_train_test_diff&quot;</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">n_standard_ojectives</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">ax_po</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span>
                    <span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ax_po</span><span class="p">))</span>
                <span class="n">ax_po</span><span class="o">.</span><span class="n">write_image</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>

            <span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span> <span class="n">all_data_as_single_train_fold_y</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">get_all_data_as_single_fold</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">validation_ojective_values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">validation_objective_indexes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bs</span> <span class="ow">in</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best trial: </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">mod</span> <span class="o">=</span> <span class="n">pipe_or_model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">bs</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">all_data_as_single_train_fold_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span>
                    <span class="n">all_data_as_single_train_fold_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                    <span class="n">sk_model</span><span class="o">=</span><span class="n">mod</span><span class="p">,</span>
                    <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                        <span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span>
                        <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">all_data_as_single_train_fold_X</span><span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">input_example</span><span class="o">=</span><span class="n">all_data_as_single_train_fold_X</span><span class="p">,</span>
                    <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">validation_set_pred</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">validation_ojective_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">obj</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">validation_set_pred</span><span class="p">)</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">validation_objective_indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Validation set objective values for </span><span class="si">{</span><span class="n">validation_objective_indexes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">validation_ojective_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># plot the parity plot of the predictions</span>
                <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
                    <span class="nb">min</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
                    <span class="nb">max</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
                <span class="n">title_fontsize</span> <span class="o">=</span> <span class="mi">27</span>
                <span class="n">parity_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">xymin</span><span class="p">,</span>
                    <span class="n">xymax</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">parity_plt</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;external_validation_set_parity_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">residual_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">residual_plt</span><span class="p">,</span>
                    <span class="sa">f</span><span class="s2">&quot;external_validation_set_residual_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">err_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">err_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;external_validation_set_error_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>
                <span class="n">qq_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">qq_plt</span><span class="p">,</span> <span class="sa">f</span><span class="s2">&quot;external_validation_set_qq_plot_fold_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">.png&quot;</span>
                <span class="p">)</span>

            <span class="n">validation_metric_tab_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">validation_ojective_values</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="n">validation_objective_indexes</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index_label</span><span class="o">=</span><span class="s2">&quot;model&quot;</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_html</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">,</span> <span class="n">index_names</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">)</span>

            <span class="n">studies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">studies</span><span class="p">,</span> <span class="n">experiment_id</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.run_train_test_study_with_mlflow">
    <p>def <span class="ident">run_train_test_study_with_mlflow</span>(</p><p>models: List[redxregressors.classical_ml_models.skmodel], cls: tune.build_train_test_objective, priors_dict: Optional[dict], holdout_set: Union[tune.JoinKfoldData, deepchem.data.datasets.NumpyDataset, deepchem.data.datasets.DiskDataset], num_trials: int, directions: List[str], mlflow_experiment_name: str, experiment_id: Optional[int] = None, pipeline_list: Optional[List[Tuple[str, Callable]]] = None, local_abs_store_path: Optional[str] = None, model_key_in_pipeline: Optional[str] = &#39;model&#39;, sampler: optuna.samplers._base.BaseSampler = &lt;optuna.samplers._tpe.sampler.TPESampler object at 0x342f322d0&gt;, training_smiles: Optional[List[str]] = None, experiment_description: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to run a kfold study with mlflow logging the results and models for each trial
Args:
    models (List[classical_ml_models.skmodel]): The models to run the kfold study on
    cls (build_train_test_objective): The class object to run the train test study
    pipe_or_model (Union[Pipeline, Callable]): The pipeline or model to optimize
    priors_dict (Optional[dict]): The priors to optimize over
    holdout_set (Union[JoinKfoldData, deepchem.data.NumpyDataset, deepchem.data.DiskDataset]): The holdout set to validate the models
    num_trials (int): The number of trials to run
    experiment_id (int): The mlflow experiment id
    directions (List[str]): The directions to optimize the objectives in
    mlflow_experiment_name (str): The mlflow experiment name
    local_abs_store_path (Optional[str], optional): The local absolute path to store the models. Defaults to None.
    model_key_in_pipeline (Optional[str], optional): The key to prepend to the model parameters in the pipeline. Defaults to "model__".
    sampler (optuna.samplers.BaseSampler, optional): The sampler to use for the optimization. Defaults to optuna.samplers.TPESampler(seed=utilities.random_seed).</p>
<p>Returns:
    tuple[list[Any], int]: The studies and the experiment id</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.run_train_test_study_with_mlflow', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.run_train_test_study_with_mlflow" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">run_train_test_study_with_mlflow</span><span class="p">(</span>
    <span class="n">models</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">],</span>
    <span class="bp">cls</span><span class="p">:</span> <span class="n">build_train_test_objective</span><span class="p">,</span>
    <span class="n">priors_dict</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">],</span>
    <span class="n">holdout_set</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span>
        <span class="n">JoinKfoldData</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">NumpyDataset</span><span class="p">,</span> <span class="n">deepchem</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">DiskDataset</span>
    <span class="p">],</span>
    <span class="n">num_trials</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">directions</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span>
    <span class="n">mlflow_experiment_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">pipeline_list</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Tuple</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Callable</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">local_abs_store_path</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">model_key_in_pipeline</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;model&quot;</span><span class="p">,</span>
    <span class="n">sampler</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">BaseSampler</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">samplers</span><span class="o">.</span><span class="n">TPESampler</span><span class="p">(</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">training_smiles</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">tuple</span><span class="p">[</span><span class="nb">list</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="nb">int</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to run a kfold study with mlflow logging the results and models for each trial</span>
<span class="sd">    Args:</span>
<span class="sd">        models (List[classical_ml_models.skmodel]): The models to run the kfold study on</span>
<span class="sd">        cls (build_train_test_objective): The class object to run the train test study</span>
<span class="sd">        pipe_or_model (Union[Pipeline, Callable]): The pipeline or model to optimize</span>
<span class="sd">        priors_dict (Optional[dict]): The priors to optimize over</span>
<span class="sd">        holdout_set (Union[JoinKfoldData, deepchem.data.NumpyDataset, deepchem.data.DiskDataset]): The holdout set to validate the models</span>
<span class="sd">        num_trials (int): The number of trials to run</span>
<span class="sd">        experiment_id (int): The mlflow experiment id</span>
<span class="sd">        directions (List[str]): The directions to optimize the objectives in</span>
<span class="sd">        mlflow_experiment_name (str): The mlflow experiment name</span>
<span class="sd">        local_abs_store_path (Optional[str], optional): The local absolute path to store the models. Defaults to None.</span>
<span class="sd">        model_key_in_pipeline (Optional[str], optional): The key to prepend to the model parameters in the pipeline. Defaults to &quot;model__&quot;.</span>
<span class="sd">        sampler (optuna.samplers.BaseSampler, optional): The sampler to use for the optimization. Defaults to optuna.samplers.TPESampler(seed=utilities.random_seed).</span>

<span class="sd">    Returns:</span>
<span class="sd">        tuple[list[Any], int]: The studies and the experiment id</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">store_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">local_abs_store_path</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
            <span class="n">store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">experiment_id</span> <span class="o">=</span> <span class="n">ml_flow_funcs</span><span class="o">.</span><span class="n">setup_for_mlflow</span><span class="p">(</span>
        <span class="n">mlflow_experiment_name</span><span class="p">,</span> <span class="n">utilities</span><span class="o">.</span><span class="n">mlflow_local_uri</span>
    <span class="p">)</span>

    <span class="c1"># if training_smiles is given automatically create an applicability domain based on Tanimoto distance/similarity model and log it to mlflow.</span>
    <span class="c1"># It is the same for all prediction models.</span>
    <span class="k">if</span> <span class="n">training_smiles</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="s2">&quot;Applicability_domain&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Training smiles: </span><span class="si">{</span><span class="n">training_smiles</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="n">admodel</span> <span class="o">=</span> <span class="n">applicability_domain</span><span class="o">.</span><span class="n">get_tanimoto_ad_model</span><span class="p">(</span>
                <span class="n">training_smiles</span><span class="o">=</span><span class="n">training_smiles</span><span class="p">,</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">algorithm</span><span class="o">=</span><span class="s2">&quot;brute&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">wadmodel</span> <span class="o">=</span> <span class="n">WrappedKNeighbors</span><span class="p">(</span><span class="n">admodel</span><span class="p">)</span>
            <span class="n">example_input</span> <span class="o">=</span> <span class="n">ml_featurization</span><span class="o">.</span><span class="n">get_ecfp</span><span class="p">(</span>
                <span class="n">smiles</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;c1ccccc1&quot;</span><span class="p">,</span> <span class="s2">&quot;CCCCC&quot;</span><span class="p">,</span> <span class="s2">&quot;C(CCN)C(=O)O&quot;</span><span class="p">,</span> <span class="s2">&quot;c1ccccc1NC(=O)C&quot;</span><span class="p">],</span>
                <span class="n">radius</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                <span class="n">hash_length</span><span class="o">=</span><span class="mi">1024</span><span class="p">,</span>
                <span class="n">return_np</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                <span class="n">sk_model</span><span class="o">=</span><span class="n">wadmodel</span><span class="p">,</span>
                <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;applicability_domain_model&quot;</span><span class="p">,</span>
                <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                    <span class="n">example_input</span><span class="p">,</span> <span class="n">wadmodel</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">example_input</span><span class="p">)</span>
                <span class="p">),</span>
                <span class="n">registered_model_name</span><span class="o">=</span><span class="s2">&quot;applicability_domain_kneighbours_tanimoto_distance_model&quot;</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_training_points&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_samples_fit_</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_metric</span><span class="p">(</span><span class="s2">&quot;number_of_features&quot;</span><span class="p">,</span> <span class="n">admodel</span><span class="o">.</span><span class="n">n_features_in_</span><span class="p">)</span>

    <span class="n">studies</span> <span class="o">=</span> <span class="p">[]</span>

    <span class="k">for</span> <span class="n">m</span> <span class="ow">in</span> <span class="n">models</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">classical_ml_models</span><span class="o">.</span><span class="n">skmodel</span><span class="p">):</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model </span><span class="si">{</span><span class="n">m</span><span class="si">}</span><span class="s2"> is not an instance of skmodel&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">date</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="n">date_and_time</span> <span class="o">=</span> <span class="n">datetime</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="n">datetime</span><span class="o">.</span><span class="n">now</span><span class="p">(),</span> <span class="s2">&quot;</span><span class="si">%d</span><span class="s2">-%m-%Y_%H-%M&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">model_store_path</span> <span class="o">=</span> <span class="n">store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;kfold_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">date</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="n">store_path</span><span class="o">.</span><span class="n">exists</span><span class="p">():</span>
                <span class="n">model_store_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">priors_dict</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">default_param_range_priors</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">priors_dict</span>

        <span class="k">if</span> <span class="n">pipeline_list</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">Pipeline</span><span class="p">(</span><span class="n">pipeline_list</span> <span class="o">+</span> <span class="p">[(</span><span class="n">model_key_in_pipeline</span><span class="p">,</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span><span class="p">)])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">pipe_or_model</span> <span class="o">=</span> <span class="n">m</span><span class="o">.</span><span class="n">model</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Model: </span><span class="si">{</span><span class="n">pipe_or_model</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">pipe_or_model</span><span class="p">,</span> <span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">priors</span> <span class="o">=</span> <span class="n">utilities</span><span class="o">.</span><span class="n">prepend_dictionary_keys</span><span class="p">(</span>
                <span class="n">priors</span><span class="p">,</span> <span class="n">prepend</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">model_key_in_pipeline</span><span class="si">}</span><span class="s2">__&quot;</span>
            <span class="p">)</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Priors: </span><span class="si">{</span><span class="n">priors</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>

        <span class="n">name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;train_test_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">sampler</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span>

        <span class="k">if</span> <span class="n">local_abs_store_path</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;sqlite:///</span><span class="si">{</span><span class="n">model_store_path</span><span class="o">.</span><span class="n">joinpath</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s1">_</span><span class="si">{</span><span class="n">date_and_time</span><span class="si">}</span><span class="s1">.db&#39;</span><span class="p">)</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">study</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">create_study</span><span class="p">(</span>
                <span class="n">study_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;library_prod_</span><span class="si">{</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="n">sampler</span><span class="o">=</span><span class="n">sampler</span><span class="p">,</span>
                <span class="n">storage</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                <span class="n">load_if_exists</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
                <span class="n">directions</span><span class="o">=</span><span class="n">directions</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;For model </span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2"> we will run </span><span class="si">{</span><span class="n">num_trials</span><span class="si">}</span><span class="s2"> trials to optimize the hyperparameters&quot;</span>
        <span class="p">)</span>
        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_training_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="n">study</span><span class="o">.</span><span class="n">optimize</span><span class="p">(</span>
                <span class="k">lambda</span> <span class="n">trial</span><span class="p">:</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectivefx</span><span class="p">(</span>
                    <span class="n">trial</span><span class="p">,</span>
                    <span class="n">pipe_or_model</span><span class="p">,</span>
                    <span class="n">priors</span><span class="p">,</span>
                    <span class="n">name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train_and_testing_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
                    <span class="n">experiment_description</span><span class="o">=</span><span class="n">experiment_description</span><span class="p">,</span>
                <span class="p">),</span>
                <span class="n">n_trials</span><span class="o">=</span><span class="n">num_trials</span><span class="p">,</span>
                <span class="n">show_progress_bar</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                <span class="n">gc_after_trial</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="p">)</span>

        <span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">(</span>
            <span class="n">experiment_id</span><span class="o">=</span><span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">run_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_runs&quot;</span><span class="p">,</span>
            <span class="n">nested</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">):</span>
            <span class="c1"># Account for the absolute difference between the training and test set scores if its an objective</span>
            <span class="n">n_standard_ojectives</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">)</span>
            <span class="k">if</span> <span class="bp">cls</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
                <span class="n">n_standard_ojectives</span> <span class="o">+=</span> <span class="mi">1</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span>
                    <span class="s2">&quot;abs_train_test_diff&quot;</span>
                <span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">target_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>

            <span class="k">if</span> <span class="n">n_standard_ojectives</span> <span class="o">&lt;=</span> <span class="mi">3</span><span class="p">:</span>
                <span class="n">ax_po</span> <span class="o">=</span> <span class="n">optuna</span><span class="o">.</span><span class="n">visualization</span><span class="o">.</span><span class="n">plot_pareto_front</span><span class="p">(</span>
                    <span class="n">study</span><span class="p">,</span> <span class="n">target_names</span><span class="o">=</span><span class="n">target_names</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">ax_po</span><span class="p">))</span>
                <span class="n">ax_po</span><span class="o">.</span><span class="n">write_image</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pareto_front_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">.png&quot;</span><span class="p">)</span>

            <span class="n">all_data_as_single_train_set_x</span><span class="p">,</span> <span class="n">all_data_as_single_train_set_y</span> <span class="o">=</span> <span class="p">(</span>
                <span class="bp">cls</span><span class="o">.</span><span class="n">get_all_data_as_single_set</span><span class="p">()</span>
            <span class="p">)</span>

            <span class="n">validation_ojective_values</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="n">validation_objective_indexes</span> <span class="o">=</span> <span class="p">[]</span>
            <span class="k">for</span> <span class="n">bs</span> <span class="ow">in</span> <span class="n">study</span><span class="o">.</span><span class="n">best_trials</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Best trial: </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2"> </span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">mod</span> <span class="o">=</span> <span class="n">pipe_or_model</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">bs</span><span class="o">.</span><span class="n">params</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="n">all_data_as_single_train_set_y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
                <span class="n">mod</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">all_data_as_single_train_set_x</span><span class="p">,</span>
                    <span class="n">all_data_as_single_train_set_y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">sklearn</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
                    <span class="n">sk_model</span><span class="o">=</span><span class="n">mod</span><span class="p">,</span>
                    <span class="n">artifact_path</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                    <span class="n">signature</span><span class="o">=</span><span class="n">mlflow</span><span class="o">.</span><span class="n">models</span><span class="o">.</span><span class="n">infer_signature</span><span class="p">(</span>
                        <span class="n">all_data_as_single_train_set_x</span><span class="p">,</span>
                        <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">all_data_as_single_train_set_x</span><span class="p">),</span>
                    <span class="p">),</span>
                    <span class="n">input_example</span><span class="o">=</span><span class="n">all_data_as_single_train_set_x</span><span class="p">,</span>
                    <span class="n">registered_model_name</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;train_test_</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_model_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">validation_set_pred</span> <span class="o">=</span> <span class="n">mod</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">X</span><span class="p">)</span>
                <span class="n">validation_ojective_values</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">[</span><span class="n">obj</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="p">,</span> <span class="n">validation_set_pred</span><span class="p">)</span> <span class="k">for</span> <span class="n">obj</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">]</span>
                <span class="p">)</span>
                <span class="n">validation_objective_indexes</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">bs</span><span class="o">.</span><span class="n">number</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
                    <span class="sa">f</span><span class="s2">&quot;Validation set objective values for </span><span class="si">{</span><span class="n">validation_objective_indexes</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">: </span><span class="si">{</span><span class="n">validation_ojective_values</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span>
                <span class="p">)</span>

                <span class="c1"># plot the parity plot of the predictions</span>
                <span class="n">xymin</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">floor</span><span class="p">(</span>
                    <span class="nb">min</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">xymax</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ceil</span><span class="p">(</span>
                    <span class="nb">max</span><span class="p">(</span><span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="o">+</span> <span class="n">validation_set_pred</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span>
                <span class="p">)</span>
                <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;min </span><span class="si">{</span><span class="n">xymin</span><span class="si">}</span><span class="s2">, max </span><span class="si">{</span><span class="n">xymax</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
                <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
                <span class="n">title_fontsize</span> <span class="o">=</span> <span class="mi">27</span>
                <span class="n">parity_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">parity_plot</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">xymin</span><span class="p">,</span>
                    <span class="n">xymax</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">parity_plt</span><span class="p">,</span>
                    <span class="s2">&quot;external_validation_set_parity_plot_train_test_validation.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">residual_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_residuals</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">residual_plt</span><span class="p">,</span>
                    <span class="s2">&quot;external_validation_set_residual_plot_train_test_validation.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">err_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_prediction_error</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">err_plt</span><span class="p">,</span>
                    <span class="s2">&quot;external_validation_set_error_plot_train_test_validation.png&quot;</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">qq_plt</span> <span class="o">=</span> <span class="n">build_kfold_objective</span><span class="o">.</span><span class="n">plot_qq</span><span class="p">(</span>
                    <span class="n">holdout_set</span><span class="o">.</span><span class="n">y</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
                    <span class="n">validation_set_pred</span><span class="p">,</span>
                    <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span>
                    <span class="n">title_fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">,</span>
                <span class="p">)</span>
                <span class="n">mlflow</span><span class="o">.</span><span class="n">log_figure</span><span class="p">(</span>
                    <span class="n">qq_plt</span><span class="p">,</span> <span class="s2">&quot;external_validation_set_qq_plot_train_test_validation.png&quot;</span>
                <span class="p">)</span>

            <span class="n">validation_metric_tab_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                <span class="n">validation_ojective_values</span><span class="p">,</span>
                <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="n">ent</span><span class="o">.</span><span class="vm">__name__</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="bp">cls</span><span class="o">.</span><span class="n">objectives</span><span class="p">],</span>
                <span class="n">index</span><span class="o">=</span><span class="n">validation_objective_indexes</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">,</span> <span class="n">index_label</span><span class="o">=</span><span class="s2">&quot;model&quot;</span>
            <span class="p">)</span>
            <span class="n">validation_metric_tab_df</span><span class="o">.</span><span class="n">to_html</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">,</span> <span class="n">index_names</span><span class="o">=</span><span class="kc">True</span>
            <span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.csv&quot;</span><span class="p">)</span>
            <span class="n">mlflow</span><span class="o">.</span><span class="n">log_artifact</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">m</span><span class="o">.</span><span class="n">name</span><span class="si">}</span><span class="s2">_validation_metrics.html&quot;</span><span class="p">)</span>

            <span class="n">studies</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">study</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">studies</span><span class="p">,</span> <span class="n">experiment_id</span>
</pre></div>

  </div>
</div>

  </div>


    <h2 class="section-title" id="header-classes">Classes</h2>

      <div class="item">
      <p id="redxregressors.tune.JoinKfoldData" class="name">class <span class="ident">JoinKfoldData</span></p>


    <div class="desc"><p>JoinKfoldData(X: numpy.ndarray, y: numpy.ndarray)</p></div>
  <div class="source_cont">
</div>


      <div class="class">
      </div>
      </div>

      <div class="item">
      <p id="redxregressors.tune.WrappedKNeighbors" class="name">class <span class="ident">WrappedKNeighbors</span></p>


  <div class="source_cont">
</div>


      <div class="class">
          <h3>Methods</h3>

  <div class="item">
    <div class="name def" id="redxregressors.tune.WrappedKNeighbors.predict">
    <p>def <span class="ident">predict</span>(</p><p>self, X: numpy.ndarray, n_neighbors: int = 1, **kwargs)</p>
    </div>




  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.WrappedKNeighbors.predict', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.WrappedKNeighbors.predict" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
    <span class="n">distances</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">kneighbors</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">n_neighbors</span><span class="o">=</span><span class="n">n_neighbors</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">distances</span>
</pre></div>

  </div>
</div>

  </div>

      </div>
      </div>

      <div class="item">
      <p id="redxregressors.tune.build_kfold_objective" class="name">class <span class="ident">build_kfold_objective</span></p>


  <div class="source_cont">
</div>


      <div class="class">
          <h3>Static methods</h3>

  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.parity_plot">
    <p>def <span class="ident">parity_plot</span>(</p><p>y_test, y_pred, xymin, xymax, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the parity plot of the test set predictions
Args:
    y_test (JoinKfoldData): The test set data
    y_pred (np.ndarray): The predicted values
    xymin (float): The minimum value for the x and y axis
    xymax (float): The maximum value for the x and y axis
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to</p>
<p>Returns:
    plt.Figure: The parity plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.parity_plot', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.parity_plot" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">parity_plot</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">xymin</span><span class="p">,</span>
    <span class="n">xymax</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the parity plot of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (JoinKfoldData): The test set data</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        xymin (float): The minimum value for the x and y axis</span>
<span class="sd">        xymax (float): The maximum value for the x and y axis</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: The parity plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Least squares regression line</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">deg</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xseq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1"># plot the parity plot figure</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prefect Prediction&quot;</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s2">&quot;#89a0b0&quot;</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="p">[</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;x = y&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">xseq</span><span class="p">,</span> <span class="n">m</span> <span class="o">*</span> <span class="n">xseq</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="s2">&quot;m-.&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Least Squares Regression Line&quot;</span>
        <span class="p">)</span>  <span class="c1"># y = mx + c</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">y_test</span><span class="p">,</span>
            <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Model predictions RMSE: </span><span class="si">{</span><span class="n">root_mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> R2 Coefficent of determination </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Experimental&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test Set Experimental Vs. Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.plot_prediction_error">
    <p>def <span class="ident">plot_prediction_error</span>(</p><p>y_test, y_pred, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the prediction error plot of the test set predictions
Args:
    y_test (np.ndarray): The test set target values
    y_pred (np.ndarray): The predicted values
    style (str): The style of the plot
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to</p>
<p>Returns:
    plt.Figure: The prediction error plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.plot_prediction_error', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.plot_prediction_error" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_prediction_error</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the prediction error plot of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (np.ndarray): The test set target values</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        style (str): The style of the plot</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: The prediction error plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Error Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predictions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Errors&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.plot_qq">
    <p>def <span class="ident">plot_qq</span>(</p><p>y_test, y_pred, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the QQ plot of the residuals of the test set predictions
Args:
    y_test (np.ndarray): The test set target values
    y_pred (np.ndarray): The predicted values
    style (str): The style of the plot
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to
Returns:
    plt.Figure: The QQ plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.plot_qq', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.plot_qq" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_qq</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the QQ plot of the residuals of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (np.ndarray): The test set target values</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        style (str): The style of the plot</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: The QQ plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;QQ Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Theoretical Quantiles&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Ordered Values&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.plot_residuals">
    <p>def <span class="ident">plot_residuals</span>(</p><p>y_test, y_pred, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the residuals of the test set predictions
Args:
    y_test (np.ndarray): The test set target values
    y_pred (np.ndarray): The predicted values
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to</p>
<p>Returns:
    plt.figure: The residuals plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.plot_residuals', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.plot_residuals" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_residuals</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the residuals of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (np.ndarray): The test set target values</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.figure: The residuals plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">residplot</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">lowess</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
            <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;lw&quot;</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">},</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Residual Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>

          <h3>Methods</h3>

  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.abs_train_test_diff_objective">
    <p>def <span class="ident">abs_train_test_diff_objective</span>(</p><p>self, train_scores: numpy.ndarray, test_scores: numpy.ndarray)</p>
    </div>




    <div class="desc"><p>Function to calculate the difference between the training and test set scores. This is used as a restraining metric to prevent overfitting.
Note this is the difference between the mean scores for all other objectives on all folds of the k fold.
Args:
    train_scores (np.ndarray): The training set scores
    test_scores (np.ndarray): The test set scores
Returns:
    float: The absolute difference between the training and test set scores</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.abs_train_test_diff_objective', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.abs_train_test_diff_objective" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">abs_train_test_diff_objective</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to calculate the difference between the training and test set scores. This is used as a restraining metric to prevent overfitting.</span>
<span class="sd">    Note this is the difference between the mean scores for all other objectives on all folds of the k fold.</span>
<span class="sd">    Args:</span>
<span class="sd">        train_scores (np.ndarray): The training set scores</span>
<span class="sd">        test_scores (np.ndarray): The test set scores</span>
<span class="sd">    Returns:</span>
<span class="sd">        float: The absolute difference between the training and test set scores</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.build_param_grid">
    <p>def <span class="ident">build_param_grid</span>(</p><p>self, parameters, trial: optuna.trial._trial.Trial, param_grid: Optional[dict] = None)</p>
    </div>




    <div class="desc"><p>Function to build the parameter grid for the optimization
Args:
    parameters (dict): The parameters to optimize over
    trial (optuna.trial.Trial): The optuna trial object
    param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.
Returns:
    dict[Any, Any]: The parameter grid</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.build_param_grid', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.build_param_grid" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">build_param_grid</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build the parameter grid for the optimization</span>
<span class="sd">    Args:</span>
<span class="sd">        parameters (dict): The parameters to optimize over</span>
<span class="sd">        trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">        param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict[Any, Any]: The parameter grid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;catagorical&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">param_grid</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.get_all_data_as_single_fold">
    <p>def <span class="ident">get_all_data_as_single_fold</span>(</p><p>self, kf: Optional[List[Tuple[Union[numpy.ndarray, deepchem.data.datasets.DiskDataset], Union[numpy.ndarray, deepchem.data.datasets.DiskDataset]]]] = None)</p>
    </div>




    <div class="desc"><p>Function to get all the data as a single fold. It combines each test set from the k fold into a single set. This is useful for training a model on all the data.
The returned data is a tuple of the features and target values as numpy.
Returns:
    Tuple[np.ndarray, np.ndarray]: The features and target values</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.get_all_data_as_single_fold', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.get_all_data_as_single_fold" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_all_data_as_single_fold</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">kf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">List</span><span class="p">[</span>
            <span class="n">Tuple</span><span class="p">[</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to get all the data as a single fold. It combines each test set from the k fold into a single set. This is useful for training a model on all the data.</span>
<span class="sd">    The returned data is a tuple of the features and target values as numpy.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Tuple[np.ndarray, np.ndarray]: The features and target values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">kf</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">])</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">test</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">_</span><span class="p">,</span> <span class="n">test</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.get_data">
    <p>def <span class="ident">get_data</span>(</p><p>self, X: Union[pandas.core.frame.DataFrame, numpy.ndarray, NoneType] = None, y: Union[numpy.ndarray, pandas.core.series.Series, NoneType] = None, kf: Optional[List[Tuple[Union[numpy.ndarray, deepchem.data.datasets.DiskDataset], Union[numpy.ndarray, deepchem.data.datasets.DiskDataset]]]] = None)</p>
    </div>




    <div class="desc"><p>Data should be passed in as either lists or tuples containing numpy arrays or pandas dataframes/Series objects to X and y
which will be randomly split into k folds or a predefined kfold object can be passed in as kf. The predefined kf should be
either a deepchem kfold object or list of tuples of JoinKfoldData classes with X and y being numpy arrays. The data is then
stored in the cv_data and cv_ids attributes of the class object.
Args:
    X (Optional[Union[np.ndarray, pd.DataFrame]]): The features
    y (Optional[Union[np.ndarray, pd.Series]]): The target values
    kf (Optional[List[Tuple[Union[np.ndarray, data.datasets.DiskDataset], Union[np.ndarray, data.datasets.DiskDataset]]]): The predefined kfold object</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.get_data', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.get_data" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_data</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">kf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">List</span><span class="p">[</span>
            <span class="n">Tuple</span><span class="p">[</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data should be passed in as either lists or tuples containing numpy arrays or pandas dataframes/Series objects to X and y</span>
<span class="sd">    which will be randomly split into k folds or a predefined kfold object can be passed in as kf. The predefined kf should be</span>
<span class="sd">    either a deepchem kfold object or list of tuples of JoinKfoldData classes with X and y being numpy arrays. The data is then</span>
<span class="sd">    stored in the cv_data and cv_ids attributes of the class object.</span>
<span class="sd">    Args:</span>
<span class="sd">        X (Optional[Union[np.ndarray, pd.DataFrame]]): The features</span>
<span class="sd">        y (Optional[Union[np.ndarray, pd.Series]]): The target values</span>
<span class="sd">        kf (Optional[List[Tuple[Union[np.ndarray, data.datasets.DiskDataset], Union[np.ndarray, data.datasets.DiskDataset]]]): The predefined kfold object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>
        <span class="n">cv</span> <span class="o">=</span> <span class="n">KFold</span><span class="p">(</span><span class="n">n_splits</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">train_indx</span><span class="p">,</span> <span class="n">test_indx</span> <span class="ow">in</span> <span class="n">cv</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">(</span>
                    <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">train_indx</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">train_indx</span><span class="p">]),</span>
                    <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X</span><span class="p">[</span><span class="n">test_indx</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">[</span><span class="n">test_indx</span><span class="p">]),</span>
                <span class="p">)</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">train_indx</span><span class="p">,</span> <span class="n">test_indx</span><span class="p">))</span>
    <span class="k">elif</span> <span class="n">kf</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="k">if</span> <span class="s2">&quot;deepchem&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">kf</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">])):</span>
                <span class="k">for</span> <span class="n">trainf</span><span class="p">,</span> <span class="n">testf</span> <span class="ow">in</span> <span class="n">kf</span><span class="p">:</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">trainf</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">trainf</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                            <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">testf</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">testf</span><span class="o">.</span><span class="n">y</span><span class="p">),</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">trainf</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">testf</span><span class="o">.</span><span class="n">ids</span><span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">kf</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">JoinKfoldData</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span> <span class="o">=</span> <span class="n">kf</span>
                    <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">trainf</span><span class="p">,</span> <span class="n">testf</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainf</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                                <span class="p">],</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_testrow_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testf</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                                <span class="p">],</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;The kfolds do not have a deepchem or JoinKfoldData object format will try to format&quot;</span>
                    <span class="p">)</span>
                    <span class="k">for</span> <span class="n">ith</span><span class="p">,</span> <span class="p">(</span><span class="n">trainf</span><span class="p">,</span> <span class="n">testf</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">kf</span><span class="p">):</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cv_data</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">trainf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">trainf</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                                <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">testf</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">testf</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
                        <span class="bp">self</span><span class="o">.</span><span class="n">cv_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                            <span class="p">(</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">trainf</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                                <span class="p">],</span>
                                <span class="p">[</span>
                                    <span class="sa">f</span><span class="s2">&quot;fold_</span><span class="si">{</span><span class="n">ith</span><span class="si">}</span><span class="s2">_testrow_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                    <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">testf</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
                                <span class="p">],</span>
                            <span class="p">)</span>
                        <span class="p">)</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;The kfolds object is not in the correct format, it should be either a deepchem kfold data object or a list of tuples of numpy arrays&quot;</span>
            <span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.objectivefx">
    <p>def <span class="ident">objectivefx</span>(</p><p>self, trial: optuna.trial._trial.Trial, regressorfx: Union[sklearn.pipeline.Pipeline, Callable], parameters: dict, update_param_grid_callback: Optional[Callable] = None, name: Optional[str] = &#39;kfold_study&#39;, experiment_id: Optional[int] = None, experiment_description: Optional[str] = None, without_mlflow: bool = False, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.
It should be used like:</p>
<pre><code class="language-python">
cls = build_kfold_objective(&quot;test&quot;, 5)
cls.get_data(X, y)
directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])

experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)

pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])

study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f'sqlite:///test.db', load_if_exists=True)

func = lambda trial: cls.objectivefx(
    trial,
    pipe,
    priors,
    name=&quot;kfold_run&quot;,
    experiment_id=experiment_id
)

study.optimize(
    func,
    n_trials=40,
)
</code></pre>
<p>Args:
    trial (optuna.trial.Trial): The optuna trial object
    regressorfx (Any): The regressor function to optimize
    parameters (dict): The parameter grid to optimize over
    update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.
    name (Optional[str], optional): The name of the study. Defaults to "kfold_study".
    experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.
    experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.
    with_mlflow (bool): Whether to use mlflow or not</p>
<p>Returns:
    Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.objectivefx', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.objectivefx" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objectivefx</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;kfold_study&quot;</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">without_mlflow</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.</span>
<span class="sd">    It should be used like:</span>
<span class="sd">    ```python</span>
<span class="sd">    cls = build_kfold_objective(&quot;test&quot;, 5)</span>
<span class="sd">    cls.get_data(X, y)</span>
<span class="sd">    directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])</span>
<span class="sd">    experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)</span>
<span class="sd">    pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])</span>
<span class="sd">    study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f&#39;sqlite:///test.db&#39;, load_if_exists=True)</span>
<span class="sd">    func = lambda trial: cls.objectivefx(</span>
<span class="sd">        trial,</span>
<span class="sd">        pipe,</span>
<span class="sd">        priors,</span>
<span class="sd">        name=&quot;kfold_run&quot;,</span>
<span class="sd">        experiment_id=experiment_id</span>
<span class="sd">    )</span>
<span class="sd">    study.optimize(</span>
<span class="sd">        func,</span>
<span class="sd">        n_trials=40,</span>
<span class="sd">    )</span>
<span class="sd">    ```</span>
<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">        regressorfx (Any): The regressor function to optimize</span>
<span class="sd">        parameters (dict): The parameter grid to optimize over</span>
<span class="sd">        update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.</span>
<span class="sd">        name (Optional[str], optional): The name of the study. Defaults to &quot;kfold_study&quot;.</span>
<span class="sd">        experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.</span>
<span class="sd">        experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</span>
<span class="sd">        with_mlflow (bool): Whether to use mlflow or not</span>
<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">without_mlflow</span> <span class="ow">is</span> <span class="kc">False</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_with_mlflow</span><span class="p">(</span>
            <span class="n">trial</span><span class="p">,</span>
            <span class="n">regressorfx</span><span class="p">,</span>
            <span class="n">parameters</span><span class="p">,</span>
            <span class="n">update_param_grid_callback</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">experiment_description</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_without_mlflow</span><span class="p">(</span>
            <span class="n">trial</span><span class="p">,</span>
            <span class="n">regressorfx</span><span class="p">,</span>
            <span class="n">parameters</span><span class="p">,</span>
            <span class="n">update_param_grid_callback</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">experiment_description</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_kfold_objective.set_objectives">
    <p>def <span class="ident">set_objectives</span>(</p><p>self, objectives: Optional[List[Callable]] = None, directions: Optional[List[str]] = None, add_train_test_diff_objective: bool = False)</p>
    </div>




    <div class="desc"><p>Set the objectives and directions for the optimization. These should be metrics with an interface of objective = func(y_true, y_pred) and direction to be one of ["minimize", "maximize"].
If add_train_test_diff_objective is set to True the difference between the training and test set scores will be added as an objective to minimize. This provides a restraining metric to prevent overfitting.
Args:
    objectives (Optional[List[Callable]]): A list of objective functions to optimize
    directions (Optional[List[str]]): A list of directions to optimize the objectives in
    add_train_test_diff_objective (bool): Whether to add a restraining metric to prevent overfitting
Returns:
    List[str]: A list of directions to optimize the objectives</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_kfold_objective.set_objectives', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_kfold_objective.set_objectives" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_objectives</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">objectives</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">directions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">add_train_test_diff_objective</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the objectives and directions for the optimization. These should be metrics with an interface of objective = func(y_true, y_pred) and direction to be one of [&quot;minimize&quot;, &quot;maximize&quot;].</span>
<span class="sd">    If add_train_test_diff_objective is set to True the difference between the training and test set scores will be added as an objective to minimize. This provides a restraining metric to prevent overfitting.</span>
<span class="sd">    Args:</span>
<span class="sd">        objectives (Optional[List[Callable]]): A list of objective functions to optimize</span>
<span class="sd">        directions (Optional[List[str]]): A list of directions to optimize the objectives in</span>
<span class="sd">        add_train_test_diff_objective (bool): Whether to add a restraining metric to prevent overfitting</span>
<span class="sd">    Returns:</span>
<span class="sd">        List[str]: A list of directions to optimize the objectives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">objectives</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="p">[</span><span class="n">root_mean_squared_error</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="n">objectives</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="n">directions</span>
    <span class="c1"># self.objective_values = [np.zeros(self.k) for _ in range(len(self.objectives))]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">))</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">k</span><span class="p">)]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="o">=</span> <span class="n">add_train_test_diff_objective</span>
    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="c1"># log.debug(&quot;LOOK HERE: ADDED TRAIN TEST DIFF OBJECTIVE&quot;)</span>
        <span class="c1"># log.debug(f&quot;Before adding {self.objective_values}&quot;)</span>
        <span class="c1"># self.objective_values = np.array(</span>
        <span class="c1">#     [np.append(ent, [0.0]) for ent in self.objective_values]</span>
        <span class="c1"># )</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After adding </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="c1"># self.objectives += [self.abs_train_test_diff_objective]</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Not added train test diff objective as requested&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>

      </div>
      </div>

      <div class="item">
      <p id="redxregressors.tune.build_train_test_objective" class="name">class <span class="ident">build_train_test_objective</span></p>


  <div class="source_cont">
</div>


      <div class="class">
          <h3>Static methods</h3>

  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.parity_plot">
    <p>def <span class="ident">parity_plot</span>(</p><p>y_test, y_pred, xymin, xymax, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the parity plot of the test set predictions
Args:
    y_test (JoinKfoldData): The test set data
    y_pred (np.ndarray): The predicted values
    xymin (float): The minimum value for the x and y axis
    xymax (float): The maximum value for the x and y axis
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to
Returns:
    plt.Figure: The parity plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.parity_plot', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.parity_plot" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">parity_plot</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">xymin</span><span class="p">,</span>
    <span class="n">xymax</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the parity plot of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (JoinKfoldData): The test set data</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        xymin (float): The minimum value for the x and y axis</span>
<span class="sd">        xymax (float): The maximum value for the x and y axis</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: The parity plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Least squares regression line</span>
    <span class="n">m</span><span class="p">,</span> <span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">polyfit</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">deg</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">xseq</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">,</span> <span class="n">num</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>
    <span class="c1"># plot the parity plot figure</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">ticks</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">y_test</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Prefect Prediction&quot;</span><span class="p">,</span>
            <span class="n">c</span><span class="o">=</span><span class="s2">&quot;#89a0b0&quot;</span><span class="p">,</span>
            <span class="n">alpha</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="p">[</span><span class="n">xymin</span><span class="p">,</span> <span class="n">xymax</span><span class="p">],</span> <span class="s2">&quot;k--&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;x = y&quot;</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
            <span class="n">xseq</span><span class="p">,</span> <span class="n">m</span> <span class="o">*</span> <span class="n">xseq</span> <span class="o">+</span> <span class="n">c</span><span class="p">,</span> <span class="s2">&quot;m-.&quot;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Least Squares Regression Line&quot;</span>
        <span class="p">)</span>  <span class="c1"># y = mx + c</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span>
            <span class="n">y_test</span><span class="p">,</span>
            <span class="n">y_pred</span><span class="o">.</span><span class="n">ravel</span><span class="p">(),</span>
            <span class="n">label</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Model predictions RMSE: </span><span class="si">{</span><span class="n">root_mean_squared_error</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> R2 Coefficent of determination </span><span class="si">{</span><span class="n">r2_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="w"> </span><span class="n">y_pred</span><span class="p">)</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s2">&quot;Experimental&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Test Set Experimental Vs. Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">gca</span><span class="p">()</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="n">ticks</span><span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.plot_prediction_error">
    <p>def <span class="ident">plot_prediction_error</span>(</p><p>y_test, y_pred, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the prediction error plot of the test set predictions
Args:
    y_test (np.ndarray): The test set target values
    y_pred (np.ndarray): The predicted values
    style (str): The style of the plot
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to</p>
<p>Returns:
    plt.Figure: The prediction error plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.plot_prediction_error', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.plot_prediction_error" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_prediction_error</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the prediction error plot of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (np.ndarray): The test set target values</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        style (str): The style of the plot</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: The prediction error plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;-.&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Prediction Error Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Predictions&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Errors&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.plot_qq">
    <p>def <span class="ident">plot_qq</span>(</p><p>y_test, y_pred, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the QQ plot of the residuals of the test set predictions
Args:
    y_test (np.ndarray): The test set target values
    y_pred (np.ndarray): The predicted values
    style (str): The style of the plot
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to
Returns:
    plt.Figure: The QQ plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.plot_qq', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.plot_qq" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_qq</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the QQ plot of the residuals of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (np.ndarray): The test set target values</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        style (str): The style of the plot</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.Figure: The QQ plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;LOOK: </span><span class="si">{</span><span class="n">fname</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">scipy</span><span class="o">.</span><span class="n">stats</span><span class="o">.</span><span class="n">probplot</span><span class="p">(</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">dist</span><span class="o">=</span><span class="s2">&quot;norm&quot;</span><span class="p">,</span> <span class="n">plot</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;QQ Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Theoretical Quantiles&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Ordered Values&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
            <span class="k">return</span> <span class="kc">None</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.plot_residuals">
    <p>def <span class="ident">plot_residuals</span>(</p><p>y_test, y_pred, style=&#39;seaborn-v0_8-dark-palette&#39;, size=(10, 10), title_fontsize: int = 27, fname: Optional[str] = None)</p>
    </div>




    <div class="desc"><p>Function to plot the residuals of the test set predictions
Args:
    y_test (np.ndarray): The test set target values
    y_pred (np.ndarray): The predicted values
    size (Tuple[int, int]): The size of the plot
    title_fontsize (int): The fontsize of the title
    fname (Optional[str]): The file name and path to save the plot to</p>
<p>Returns:
    plt.figure: The residuals plot</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.plot_residuals', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.plot_residuals" class="source">
    <div class="codehilite"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">plot_residuals</span><span class="p">(</span>
    <span class="n">y_test</span><span class="p">,</span>
    <span class="n">y_pred</span><span class="p">,</span>
    <span class="n">style</span><span class="o">=</span><span class="s2">&quot;seaborn-v0_8-dark-palette&quot;</span><span class="p">,</span>
    <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">),</span>
    <span class="n">title_fontsize</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">27</span><span class="p">,</span>
    <span class="n">fname</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to plot the residuals of the test set predictions</span>
<span class="sd">    Args:</span>
<span class="sd">        y_test (np.ndarray): The test set target values</span>
<span class="sd">        y_pred (np.ndarray): The predicted values</span>
<span class="sd">        size (Tuple[int, int]): The size of the plot</span>
<span class="sd">        title_fontsize (int): The fontsize of the title</span>
<span class="sd">        fname (Optional[str]): The file name and path to save the plot to</span>
<span class="sd">    Returns:</span>
<span class="sd">        plt.figure: The residuals plot</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">with</span> <span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">context</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="n">style</span><span class="p">):</span>
        <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="n">size</span><span class="p">)</span>
        <span class="n">sns</span><span class="o">.</span><span class="n">residplot</span><span class="p">(</span>
            <span class="n">x</span><span class="o">=</span><span class="n">y_pred</span><span class="p">,</span>
            <span class="n">y</span><span class="o">=</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">,</span>
            <span class="n">lowess</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
            <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span>
            <span class="n">line_kws</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;color&quot;</span><span class="p">:</span> <span class="s2">&quot;orange&quot;</span><span class="p">,</span> <span class="s2">&quot;lw&quot;</span><span class="p">:</span> <span class="mf">1.5</span><span class="p">},</span>
        <span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">axhline</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;black&quot;</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Residual Plot&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="n">title_fontsize</span><span class="p">)</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Prediction&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Residuals&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
        <span class="n">ax</span><span class="o">.</span><span class="n">tick_params</span><span class="p">(</span>
            <span class="n">axis</span><span class="o">=</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s2">&quot;major&quot;</span><span class="p">,</span> <span class="n">labelsize</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">title_fontsize</span> <span class="o">-</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">plt</span><span class="o">.</span><span class="n">tight_layout</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">fname</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="n">fname</span><span class="p">)</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">close</span><span class="p">(</span><span class="n">fig</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">fig</span>
</pre></div>

  </div>
</div>

  </div>

          <h3>Methods</h3>

  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.abs_train_test_diff_objective">
    <p>def <span class="ident">abs_train_test_diff_objective</span>(</p><p>self, train_scores: numpy.ndarray, test_scores: numpy.ndarray)</p>
    </div>




    <div class="desc"><p>Function to calculate the difference between the training and test set scores. This is used as a restraining metric to prevent overfitting.
Note this is the difference between the mean scores for all other objectives on all folds of the k fold.
Args:
    train_scores (np.ndarray): The training set scores
    test_scores (np.ndarray): The test set scores
Returns:
    float: The absolute difference between the training and test set scores</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.abs_train_test_diff_objective', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.abs_train_test_diff_objective" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">abs_train_test_diff_objective</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">train_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">test_scores</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to calculate the difference between the training and test set scores. This is used as a restraining metric to prevent overfitting.</span>
<span class="sd">    Note this is the difference between the mean scores for all other objectives on all folds of the k fold.</span>
<span class="sd">    Args:</span>
<span class="sd">        train_scores (np.ndarray): The training set scores</span>
<span class="sd">        test_scores (np.ndarray): The test set scores</span>
<span class="sd">    Returns:</span>
<span class="sd">        float: The absolute difference between the training and test set scores</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">train_scores</span><span class="p">)</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">test_scores</span><span class="p">))</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.build_param_grid">
    <p>def <span class="ident">build_param_grid</span>(</p><p>self, parameters, trial: optuna.trial._trial.Trial, param_grid: Optional[dict] = None)</p>
    </div>




    <div class="desc"><p>Function to build the parameter grid for the optimization
Args:
    parameters (dict): The parameters to optimize over
    trial (optuna.trial.Trial): The optuna trial object
    param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.
Returns:
    dict[Any, Any]: The parameter grid</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.build_param_grid', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.build_param_grid" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">build_param_grid</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> <span class="n">parameters</span><span class="p">,</span> <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span> <span class="n">param_grid</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="n">Any</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to build the parameter grid for the optimization</span>
<span class="sd">    Args:</span>
<span class="sd">        parameters (dict): The parameters to optimize over</span>
<span class="sd">        trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">        param_grid (Optional[dict], optional): The parameter grid to update. Defaults to None.</span>
<span class="sd">    Returns:</span>
<span class="sd">        dict[Any, Any]: The parameter grid</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">param_grid</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">param_grid</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">parameters</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;float&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_float</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">elif</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;int&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_int</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">v</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
        <span class="k">if</span> <span class="n">v</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="o">==</span> <span class="s2">&quot;catagorical&quot;</span><span class="p">:</span>
            <span class="n">param_grid</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">trial</span><span class="o">.</span><span class="n">suggest_categorical</span><span class="p">(</span><span class="n">k</span><span class="p">,</span> <span class="n">v</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">param_grid</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.get_all_data_as_single_set">
    <p>def <span class="ident">get_all_data_as_single_set</span>(</p><p>self, kf: Optional[List[Tuple[Union[numpy.ndarray, deepchem.data.datasets.DiskDataset], Union[numpy.ndarray, deepchem.data.datasets.DiskDataset]]]] = None)</p>
    </div>




    <div class="desc"><p>Function to get all the data as a single set. It combines te train and test set into a single set. This is useful for training a model on all the data.
The returned data is a tuple of the features and target values as numpy ndarrays.
Returns:
    Tuple[np.ndarray, np.ndarray]: The features and target values</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.get_all_data_as_single_set', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.get_all_data_as_single_set" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_all_data_as_single_set</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">kf</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">List</span><span class="p">[</span>
            <span class="n">Tuple</span><span class="p">[</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
                <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
            <span class="p">]</span>
        <span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to get all the data as a single set. It combines te train and test set into a single set. This is useful for training a model on all the data.</span>
<span class="sd">    The returned data is a tuple of the features and target values as numpy ndarrays.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Tuple[np.ndarray, np.ndarray]: The features and target values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">X</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">]])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">ent</span><span class="o">.</span><span class="n">y</span> <span class="k">for</span> <span class="n">ent</span> <span class="ow">in</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">test</span><span class="p">]])</span>
    <span class="k">return</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.get_data">
    <p>def <span class="ident">get_data</span>(</p><p>self, X: Union[pandas.core.frame.DataFrame, numpy.ndarray, NoneType] = None, y: Union[numpy.ndarray, pandas.core.series.Series, NoneType] = None, train_test_predefined: Optional[Tuple[Union[numpy.ndarray, deepchem.data.datasets.DiskDataset], Union[numpy.ndarray, deepchem.data.datasets.DiskDataset]]] = None, train_frac: Optional[float] = None, n_train: Optional[int] = None)</p>
    </div>




    <div class="desc"><p>Data should be passed in as either lists or tuples containing numpy arrays or pandas dataframes/Series objects to X and y
which will be randomly split into k folds or a predefined kfold object can be passed in as kf. The predefined kf should be
either a deepchem kfold object or list of tuples of JoinKfoldData classes with X and y being numpy arrays. The data is then
stored in the cv_data and cv_ids attributes of the class object.
Args:
    X (Optional[Union[np.ndarray, pd.DataFrame]]): The features
    y (Optional[Union[np.ndarray, pd.Series]]): The target values
    kf (Optional[List[Tuple[Union[np.ndarray, data.datasets.DiskDataset], Union[np.ndarray, data.datasets.DiskDataset]]]): The predefined kfold object</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.get_data', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.get_data" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">get_data</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_test_predefined</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span>
        <span class="n">Tuple</span><span class="p">[</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
            <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">data</span><span class="o">.</span><span class="n">datasets</span><span class="o">.</span><span class="n">DiskDataset</span><span class="p">],</span>
        <span class="p">]</span>
    <span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">train_frac</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">float</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">n_train</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Data should be passed in as either lists or tuples containing numpy arrays or pandas dataframes/Series objects to X and y</span>
<span class="sd">    which will be randomly split into k folds or a predefined kfold object can be passed in as kf. The predefined kf should be</span>
<span class="sd">    either a deepchem kfold object or list of tuples of JoinKfoldData classes with X and y being numpy arrays. The data is then</span>
<span class="sd">    stored in the cv_data and cv_ids attributes of the class object.</span>
<span class="sd">    Args:</span>
<span class="sd">        X (Optional[Union[np.ndarray, pd.DataFrame]]): The features</span>
<span class="sd">        y (Optional[Union[np.ndarray, pd.Series]]): The target values</span>
<span class="sd">        kf (Optional[List[Tuple[Union[np.ndarray, data.datasets.DiskDataset], Union[np.ndarray, data.datasets.DiskDataset]]]): The predefined kfold object</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># deal with the case where the data is passed in as numpy arrays or pandas dataframes</span>
    <span class="k">if</span> <span class="n">X</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">values</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">values</span>
        <span class="c1"># if the train_frac is not set then set it to the default value of 0.8</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">train_frac</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># if the n_train is not set then set it to the default value of None and use 0.8 fraction</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">n_train</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                    <span class="s2">&quot;Both the class level train_frac variable and function level train_frac argument are set to None, the train_frac will be set to the default value of 0.8&quot;</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="mf">0.8</span>
            <span class="k">elif</span> <span class="n">n_train</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">n_train</span> <span class="o">=</span> <span class="n">n_train</span>
        <span class="k">elif</span> <span class="n">train_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="o">=</span> <span class="n">train_frac</span>
        <span class="c1"># if the train_frac is set then split the data into a training and test set</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">train_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">train_frac</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
        <span class="c1"># if the n_train is set then split the data into a training and test set</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span>
                <span class="n">X</span><span class="p">,</span>
                <span class="n">y</span><span class="p">,</span>
                <span class="n">train_size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_train</span><span class="p">,</span>
                <span class="n">random_state</span><span class="o">=</span><span class="n">utilities</span><span class="o">.</span><span class="n">random_seed</span><span class="p">,</span>
                <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
            <span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_train</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_train</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span><span class="n">X</span><span class="o">=</span><span class="n">X_test</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">y_test</span><span class="p">)</span>
    <span class="c1"># deal with the case where the data is passed in as a predefined train test split</span>
    <span class="k">elif</span> <span class="n">train_test_predefined</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="c1"># if the train_test_predefined is a deepchem object then set the train and test attributes</span>
            <span class="k">if</span> <span class="s2">&quot;deepchem&quot;</span> <span class="ow">in</span> <span class="nb">str</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">])):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">y</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span>
                    <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">y</span>
                <span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                    <span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">ids</span><span class="p">,</span> <span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">ids</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="c1"># if the train_test_predefined is a list of tuples of numpy arrays then set the train and test attributes</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="c1"># if the train_test_predefined is a JoinKfoldData object then set the train and test attributes</span>
                <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">JoinKfoldData</span><span class="p">):</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="p">[</span>
                                <span class="sa">f</span><span class="s2">&quot;train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                            <span class="p">],</span>
                            <span class="p">[</span>
                                <span class="sa">f</span><span class="s2">&quot;test_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">X</span><span class="p">))</span>
                            <span class="p">],</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
                <span class="c1"># if the train_test_predefined is a list of tuples of numpy arrays then set the train and test attributes</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">log</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
                        <span class="s2">&quot;The train_test_predefined do not have a deepchem or JoinKfoldData object format will try to format&quot;</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train</span> <span class="o">=</span> <span class="n">JoinKfoldData</span><span class="p">(</span>
                        <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">test</span> <span class="o">=</span> <span class="p">(</span>
                        <span class="n">JoinKfoldData</span><span class="p">(</span>
                            <span class="n">X</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">0</span><span class="p">],</span>
                            <span class="n">y</span><span class="o">=</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="mi">1</span><span class="p">],</span>
                        <span class="p">),</span>
                    <span class="p">)</span>
                    <span class="bp">self</span><span class="o">.</span><span class="n">train_test_ids</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                        <span class="p">(</span>
                            <span class="p">[</span>
                                <span class="sa">f</span><span class="s2">&quot;train_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
                            <span class="p">],</span>
                            <span class="p">[</span>
                                <span class="sa">f</span><span class="s2">&quot;test_row_</span><span class="si">{</span><span class="n">jth</span><span class="si">}</span><span class="s2">&quot;</span>
                                <span class="k">for</span> <span class="n">jth</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">train_test_predefined</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">1</span><span class="p">]))</span>
                            <span class="p">],</span>
                        <span class="p">)</span>
                    <span class="p">)</span>
        <span class="c1"># if the train_test_predefined is not in the correct format then raise an error</span>
        <span class="k">except</span> <span class="ne">IndexError</span><span class="p">:</span>
            <span class="n">log</span><span class="o">.</span><span class="n">error</span><span class="p">(</span>
                <span class="s2">&quot;The train_test_predefined object is not in the correct format, it should be either a deepchem data object or a list of tuples of numpy arrays&quot;</span>
            <span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.objectivefx">
    <p>def <span class="ident">objectivefx</span>(</p><p>self, trial: optuna.trial._trial.Trial, regressorfx: Union[sklearn.pipeline.Pipeline, Callable], parameters: dict, update_param_grid_callback: Optional[Callable] = None, name: Optional[str] = &#39;kfold_study&#39;, experiment_id: Optional[int] = None, experiment_description: Optional[str] = None, without_mlflow: bool = False, **kwargs)</p>
    </div>




    <div class="desc"><p>Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.
It should be used like:</p>
<pre><code class="language-python">
cls = build_kfold_objective(&quot;test&quot;, 5)
cls.get_data(X, y)
directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])

experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)

pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])

study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f'sqlite:///test.db', load_if_exists=True)

func = lambda trial: cls.objectivefx(
    trial,
    pipe,
    priors,
    name=&quot;kfold_run&quot;,
    experiment_id=experiment_id
)

study.optimize(
    func,
    n_trials=40,
)
</code></pre>
<p>Args:
    trial (optuna.trial.Trial): The optuna trial object
    regressorfx (Any): The regressor function to optimize
    parameters (dict): The parameter grid to optimize over
    update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.
    name (Optional[str], optional): The name of the study. Defaults to "kfold_study".
    experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.
    experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</p>
<p>Returns:
    Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.objectivefx', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.objectivefx" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">objectivefx</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">trial</span><span class="p">:</span> <span class="n">optuna</span><span class="o">.</span><span class="n">trial</span><span class="o">.</span><span class="n">Trial</span><span class="p">,</span>
    <span class="n">regressorfx</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">Pipeline</span><span class="p">,</span> <span class="n">Callable</span><span class="p">],</span>
    <span class="n">parameters</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span>
    <span class="n">update_param_grid_callback</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">name</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;kfold_study&quot;</span><span class="p">,</span>
    <span class="n">experiment_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">experiment_description</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">without_mlflow</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
    <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span>
    <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">],</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">,</span> <span class="nb">float</span><span class="p">]],</span> <span class="nb">float</span>
<span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Function to do a k fold cross valuation over the data and return the mean scores for the objectives. This is built for use with optuna and the objective function should be a function that takes a trial object and returns the scores for the objectives.</span>
<span class="sd">    It should be used like:</span>
<span class="sd">    ```python</span>
<span class="sd">    cls = build_kfold_objective(&quot;test&quot;, 5)</span>
<span class="sd">    cls.get_data(X, y)</span>
<span class="sd">    directions = cls.set_objectives([root_mean_squared_error, r2_score], [&quot;minimize&quot;, &quot;maximize&quot;])</span>
<span class="sd">    experiment_id = ml_flow_funcs.setup_for_mlflow(&quot;kold_study_4&quot;, utilities.mlflow_local_uri)</span>
<span class="sd">    pipe = Pipeline([(&quot;scaler&quot;, MinMaxScaler()), (&quot;model&quot;, RandomForestRegressor(random_state=50))])</span>
<span class="sd">    study = optuna.create_study(directions=directions, study_name=&quot;test&quot;, storage=f&#39;sqlite:///test.db&#39;, load_if_exists=True)</span>
<span class="sd">    func = lambda trial: cls.objectivefx(</span>
<span class="sd">        trial,</span>
<span class="sd">        pipe,</span>
<span class="sd">        priors,</span>
<span class="sd">        name=&quot;kfold_run&quot;,</span>
<span class="sd">        experiment_id=experiment_id</span>
<span class="sd">    )</span>
<span class="sd">    study.optimize(</span>
<span class="sd">        func,</span>
<span class="sd">        n_trials=40,</span>
<span class="sd">    )</span>
<span class="sd">    ```</span>
<span class="sd">    Args:</span>
<span class="sd">        trial (optuna.trial.Trial): The optuna trial object</span>
<span class="sd">        regressorfx (Any): The regressor function to optimize</span>
<span class="sd">        parameters (dict): The parameter grid to optimize over</span>
<span class="sd">        update_param_grid_callback (Optional[Callable], optional): A callback function to update the parameter grid. Defaults to None.</span>
<span class="sd">        name (Optional[str], optional): The name of the study. Defaults to &quot;kfold_study&quot;.</span>
<span class="sd">        experiment_id (Optional[int], optional): The experiment id for mlflow. Defaults to None.</span>
<span class="sd">        experiment_description (Optional[str], optional): The experiment description for mlflow. Defaults to None.</span>
<span class="sd">    Returns:</span>
<span class="sd">        Tuple[Union[np.float64, float], Union[np.float64, Union[np.float64, float]], float]: The scores for the objectives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">without_mlflow</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;Training without MLFlow&quot;</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_without_mlflow</span><span class="p">(</span>
            <span class="n">trial</span><span class="p">,</span>
            <span class="n">regressorfx</span><span class="p">,</span>
            <span class="n">parameters</span><span class="p">,</span>
            <span class="n">update_param_grid_callback</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">critical</span><span class="p">(</span><span class="s2">&quot;Training with MLFlow&quot;</span><span class="p">)</span>
        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_objectivefx_with_mlflow</span><span class="p">(</span>
            <span class="n">trial</span><span class="p">,</span>
            <span class="n">regressorfx</span><span class="p">,</span>
            <span class="n">parameters</span><span class="p">,</span>
            <span class="n">update_param_grid_callback</span><span class="p">,</span>
            <span class="n">name</span><span class="p">,</span>
            <span class="n">experiment_id</span><span class="p">,</span>
            <span class="n">experiment_description</span><span class="p">,</span>
            <span class="o">**</span><span class="n">kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">return</span> <span class="n">scores</span>
</pre></div>

  </div>
</div>

  </div>


  <div class="item">
    <div class="name def" id="redxregressors.tune.build_train_test_objective.set_objectives">
    <p>def <span class="ident">set_objectives</span>(</p><p>self, objectives: Optional[List[Callable]] = None, directions: Optional[List[str]] = None, add_train_test_diff_objective: bool = False)</p>
    </div>




    <div class="desc"><p>Set the objectives and directions for the optimization. These should be metrics with an interface of objective = func(y_true, y_pred) and direction to be one of ["minimize", "maximize"].
If add_train_test_diff_objective is set to True the difference between the training and test set scores will be added as an objective to minimize. This provides a restraining metric to prevent overfitting.
Args:
    objectives (Optional[List[Callable]]): A list of objective functions to optimize
    directions (Optional[List[str]]): A list of directions to optimize the objectives in
    add_train_test_diff_objective (bool): Whether to add a restraining metric to prevent overfitting
Returns:
    List[str]: A list of directions to optimize the objectives</p></div>
  <div class="source_cont">
  <p class="source_link"><a href="javascript:void(0);" onclick="toggle('source-redxregressors.tune.build_train_test_objective.set_objectives', this);">Show source &equiv;</a></p>
  <div id="source-redxregressors.tune.build_train_test_objective.set_objectives" class="source">
    <div class="codehilite"><pre><span></span><span class="k">def</span><span class="w"> </span><span class="nf">set_objectives</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">objectives</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">directions</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">add_train_test_diff_objective</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set the objectives and directions for the optimization. These should be metrics with an interface of objective = func(y_true, y_pred) and direction to be one of [&quot;minimize&quot;, &quot;maximize&quot;].</span>
<span class="sd">    If add_train_test_diff_objective is set to True the difference between the training and test set scores will be added as an objective to minimize. This provides a restraining metric to prevent overfitting.</span>
<span class="sd">    Args:</span>
<span class="sd">        objectives (Optional[List[Callable]]): A list of objective functions to optimize</span>
<span class="sd">        directions (Optional[List[str]]): A list of directions to optimize the objectives in</span>
<span class="sd">        add_train_test_diff_objective (bool): Whether to add a restraining metric to prevent overfitting</span>
<span class="sd">    Returns:</span>
<span class="sd">        List[str]: A list of directions to optimize the objectives</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">objectives</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="p">[</span><span class="n">root_mean_squared_error</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objectives</span> <span class="o">=</span> <span class="n">objectives</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">=</span> <span class="n">directions</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objectives</span><span class="p">))</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">add_train_test_diff_objective</span> <span class="o">=</span> <span class="n">add_train_test_diff_objective</span>
    <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">add_train_test_diff_objective</span> <span class="ow">is</span> <span class="kc">True</span><span class="p">:</span>
        <span class="n">log</span><span class="o">.</span><span class="n">debug</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;After adding </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;minimize&quot;</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">objective_values</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">directions</span><span class="p">)</span>
</pre></div>

  </div>
</div>

  </div>

      </div>
      </div>

  </section>
</article>
  <div class="clear"> </div>
  <footer id="footer">
    <p>
      Generated by <a href="https://github.com/timothycrosley/pdocs">pdocs 1.2.0</a>
    </p>
  </footer>
</div>
</body>
</html>
